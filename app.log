2024-12-25 11:40:25,462 - __main__ - INFO - Successfully loaded QA model
2024-12-25 11:40:25,470 - __main__ - INFO - Starting application...
2024-12-25 11:40:25,470 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 11:40:25,470 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 11:40:25,470 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 11:40:25,510 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 11:40:25,510 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 11:40:25,521 - werkzeug - INFO -  * Restarting with stat
2024-12-25 11:40:38,741 - __main__ - INFO - Successfully loaded QA model
2024-12-25 11:40:38,749 - __main__ - INFO - Starting application...
2024-12-25 11:40:38,749 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 11:40:38,767 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 11:40:38,769 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 11:40:38,814 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 11:40:38,823 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 11:40:38,910 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:40:38] "GET / HTTP/1.1" 200 -
2024-12-25 11:40:39,066 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:40:39] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 11:40:39,407 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:40:39] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 11:41:04,513 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:41:04] "GET / HTTP/1.1" 200 -
2024-12-25 11:41:04,564 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:41:04] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 11:41:04,580 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:41:04] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 11:41:14,756 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /upload
2024-12-25 11:41:14,756 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:41:14] "[31m[1mPOST /upload HTTP/1.1[0m" 403 -
2024-12-25 11:41:43,923 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /upload
2024-12-25 11:41:43,928 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:41:43] "[31m[1mPOST /upload HTTP/1.1[0m" 403 -
2024-12-25 11:41:47,894 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:41:47] "GET / HTTP/1.1" 200 -
2024-12-25 11:41:47,943 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:41:47] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 11:41:47,968 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:41:47] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 11:41:53,935 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /upload
2024-12-25 11:41:53,943 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:41:53] "[31m[1mPOST /upload HTTP/1.1[0m" 403 -
2024-12-25 11:43:26,049 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 11:43:27,320 - werkzeug - INFO -  * Restarting with stat
2024-12-25 11:43:41,413 - __main__ - INFO - Successfully loaded QA model
2024-12-25 11:43:41,413 - __main__ - INFO - Starting application...
2024-12-25 11:43:41,413 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 11:43:41,413 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 11:43:41,413 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 11:43:41,470 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 11:43:41,478 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 11:47:32,641 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 11:47:34,115 - werkzeug - INFO -  * Restarting with stat
2024-12-25 11:49:14,684 - __main__ - INFO - Successfully loaded QA model
2024-12-25 11:49:14,684 - __main__ - INFO - Starting application...
2024-12-25 11:49:14,684 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 11:49:14,692 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 11:49:14,692 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 11:49:14,741 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 11:49:14,741 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 11:49:14,749 - werkzeug - INFO -  * Restarting with stat
2024-12-25 11:49:29,807 - __main__ - INFO - Successfully loaded QA model
2024-12-25 11:49:29,815 - __main__ - INFO - Starting application...
2024-12-25 11:49:29,815 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 11:49:29,841 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 11:49:29,841 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 11:49:29,876 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 11:49:29,889 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 11:49:30,028 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:49:30] "GET / HTTP/1.1" 200 -
2024-12-25 11:49:30,309 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:49:30] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-25 11:49:30,317 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:49:30] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 11:50:08,529 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:50:08] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 11:51:17,704 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 11:51:19,035 - werkzeug - INFO -  * Restarting with stat
2024-12-25 11:51:31,075 - __main__ - INFO - Successfully loaded QA model
2024-12-25 11:51:31,078 - __main__ - INFO - Starting application...
2024-12-25 11:51:31,078 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 11:51:31,078 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 11:51:31,078 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 11:51:31,087 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 11:51:31,094 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 11:51:31,152 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:51:31] "GET / HTTP/1.1" 200 -
2024-12-25 11:51:31,314 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:51:31] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-25 11:51:31,314 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:51:31] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 11:51:44,336 - __main__ - INFO - File saved successfully: 9f2be57f421b7c83a789183258d2fe4451a3a28feb33cee6bfedbcdce25cc450.pdf
2024-12-25 11:51:45,133 - __main__ - INFO - Temporary file removed: 9f2be57f421b7c83a789183258d2fe4451a3a28feb33cee6bfedbcdce25cc450.pdf
2024-12-25 11:51:45,133 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:51:45] "POST /upload HTTP/1.1" 200 -
2024-12-25 11:52:01,140 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:52:01] "POST /ask HTTP/1.1" 200 -
2024-12-25 11:52:23,893 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:52:23] "POST /ask HTTP/1.1" 200 -
2024-12-25 11:52:40,255 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:52:40] "POST /ask HTTP/1.1" 200 -
2024-12-25 11:56:10,234 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:56:10] "GET / HTTP/1.1" 200 -
2024-12-25 11:56:10,282 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:56:10] "GET /static/css/style.css HTTP/1.1" 200 -
2024-12-25 11:56:10,282 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:56:10] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-25 11:56:22,280 - __main__ - INFO - File saved successfully: 9af2e75196204095b1934b4d495e7cb4f6c049ee0a15e1b547dbe7319204eebd.pdf
2024-12-25 11:56:23,052 - __main__ - INFO - Temporary file removed: 9af2e75196204095b1934b4d495e7cb4f6c049ee0a15e1b547dbe7319204eebd.pdf
2024-12-25 11:56:23,053 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:56:23] "POST /upload HTTP/1.1" 200 -
2024-12-25 11:56:32,577 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:56:32] "POST /ask HTTP/1.1" 200 -
2024-12-25 11:56:32,593 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:56:32] "POST /ask HTTP/1.1" 200 -
2024-12-25 11:56:49,887 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 11:56:49] "POST /ask HTTP/1.1" 200 -
2024-12-25 12:39:29,682 - __main__ - INFO - Successfully loaded QA model
2024-12-25 12:39:29,684 - __main__ - INFO - Starting application...
2024-12-25 12:39:29,685 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 12:39:29,685 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 12:39:29,685 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 12:39:29,709 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 12:39:29,710 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 12:39:29,712 - werkzeug - INFO -  * Restarting with stat
2024-12-25 12:39:35,315 - __main__ - INFO - Successfully loaded QA model
2024-12-25 12:39:35,316 - __main__ - INFO - Starting application...
2024-12-25 12:39:35,316 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 12:39:35,317 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 12:39:35,317 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 12:39:35,321 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 12:39:35,323 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 12:39:35,367 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:39:35] "GET / HTTP/1.1" 200 -
2024-12-25 12:39:35,524 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:39:35] "GET /static/css/style.css HTTP/1.1" 200 -
2024-12-25 12:39:35,524 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:39:35] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-25 12:39:47,914 - __main__ - INFO - File saved successfully: 0e5e57f1b8832d71b53ddf45c53bb58bd506d2293d6a432a0fed295ab38393c7.pdf
2024-12-25 12:39:48,720 - __main__ - INFO - Temporary file removed: 0e5e57f1b8832d71b53ddf45c53bb58bd506d2293d6a432a0fed295ab38393c7.pdf
2024-12-25 12:39:48,722 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:39:48] "POST /upload HTTP/1.1" 200 -
2024-12-25 12:40:10,700 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:40:10] "POST /ask HTTP/1.1" 200 -
2024-12-25 12:40:10,705 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:40:10] "POST /ask HTTP/1.1" 200 -
2024-12-25 12:45:17,608 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:45:17] "GET / HTTP/1.1" 200 -
2024-12-25 12:45:17,650 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:45:17] "GET /static/css/style.css HTTP/1.1" 200 -
2024-12-25 12:49:46,846 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:49:46] "GET / HTTP/1.1" 200 -
2024-12-25 12:49:46,862 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:49:46] "GET /static/css/style.css HTTP/1.1" 200 -
2024-12-25 12:49:46,873 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:49:46] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-25 12:50:01,628 - __main__ - INFO - File saved successfully: b70fe5dc461eeb82b5ed198c9900c3c58d43222525ce84ba602201e986c1292f.pdf
2024-12-25 12:50:02,940 - __main__ - INFO - Temporary file removed: b70fe5dc461eeb82b5ed198c9900c3c58d43222525ce84ba602201e986c1292f.pdf
2024-12-25 12:50:02,947 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:50:02] "POST /upload HTTP/1.1" 200 -
2024-12-25 12:50:23,334 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 12:50:23] "POST /ask HTTP/1.1" 200 -
2024-12-25 13:40:11,633 - __main__ - INFO - Successfully loaded QA model
2024-12-25 13:40:11,634 - __main__ - INFO - Starting application...
2024-12-25 13:40:11,634 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 13:40:11,635 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 13:40:11,635 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 13:40:11,649 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 13:40:11,649 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 13:40:11,651 - werkzeug - INFO -  * Restarting with stat
2024-12-25 13:40:19,076 - __main__ - INFO - Successfully loaded QA model
2024-12-25 13:40:19,081 - __main__ - INFO - Starting application...
2024-12-25 13:40:19,081 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 13:40:19,082 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 13:40:19,083 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 13:40:19,099 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 13:40:19,108 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 13:40:19,256 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 13:40:19] "GET / HTTP/1.1" 200 -
2024-12-25 13:40:19,573 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 13:40:19] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-25 13:40:19,585 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 13:40:19] "GET /static/css/style.css HTTP/1.1" 200 -
2024-12-25 13:40:32,196 - __main__ - INFO - File saved successfully: 1f48d4f1b8d7e3667c2948542099c82e037a459bc05fc6cc2b8105c83bc49846.pdf
2024-12-25 13:40:32,989 - __main__ - INFO - Temporary file removed: 1f48d4f1b8d7e3667c2948542099c82e037a459bc05fc6cc2b8105c83bc49846.pdf
2024-12-25 13:40:32,991 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 13:40:32] "POST /upload HTTP/1.1" 200 -
2024-12-25 13:41:08,071 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 13:41:08] "POST /ask HTTP/1.1" 200 -
2024-12-25 13:41:08,223 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 13:41:08] "POST /ask HTTP/1.1" 200 -
2024-12-25 13:46:42,535 - __main__ - INFO - File saved successfully: 49ee9d5933fc9b6b11090367b8b87b7751a9bb02ddc7351c19d3d8146a3505ce.pdf
2024-12-25 13:46:42,559 - __main__ - INFO - Temporary file removed: 49ee9d5933fc9b6b11090367b8b87b7751a9bb02ddc7351c19d3d8146a3505ce.pdf
2024-12-25 13:46:42,559 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 13:46:42] "POST /upload HTTP/1.1" 200 -
2024-12-25 13:46:53,270 - __main__ - WARNING - Hallucinations detected: {'Eiffel Tower'}
2024-12-25 13:46:53,271 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 13:46:53] "POST /ask HTTP/1.1" 200 -
2024-12-25 13:47:23,561 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 13:47:23] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:40:00,492 - __main__ - INFO - Successfully loaded QA model
2024-12-25 14:40:00,492 - __main__ - INFO - Starting application...
2024-12-25 14:40:00,492 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 14:40:00,492 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 14:40:00,492 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 14:40:00,515 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 14:40:00,515 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 14:40:00,525 - werkzeug - INFO -  * Restarting with stat
2024-12-25 14:40:14,325 - __main__ - INFO - Successfully loaded QA model
2024-12-25 14:40:14,333 - __main__ - INFO - Starting application...
2024-12-25 14:40:14,333 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 14:40:14,333 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 14:40:14,333 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 14:40:14,333 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 14:40:14,342 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 14:40:57,689 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:40:57] "GET / HTTP/1.1" 200 -
2024-12-25 14:40:57,828 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:40:57] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-25 14:40:57,828 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:40:57] "GET /static/css/style.css HTTP/1.1" 200 -
2024-12-25 14:41:05,344 - __main__ - INFO - File saved successfully: 1838d4f25f652a84cb1d1bbc0bb05388202931cae1eb59bcaf81fa39d9963db7.pdf
2024-12-25 14:41:05,368 - __main__ - INFO - Temporary file removed: 1838d4f25f652a84cb1d1bbc0bb05388202931cae1eb59bcaf81fa39d9963db7.pdf
2024-12-25 14:41:05,377 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:41:05] "POST /upload HTTP/1.1" 200 -
2024-12-25 14:41:15,587 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:41:15] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:41:29,415 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.15).
2024-12-25 14:41:29,455 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:41:29] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:41:47,595 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:41:47] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:46:19,361 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.08).
2024-12-25 14:46:19,394 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:46:19] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:48:01,364 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 14:48:03,368 - werkzeug - INFO -  * Restarting with stat
2024-12-25 14:48:25,207 - __main__ - INFO - Successfully loaded QA model
2024-12-25 14:48:25,212 - __main__ - INFO - Starting application...
2024-12-25 14:48:25,212 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 14:48:25,220 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 14:48:25,224 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 14:48:25,254 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 14:48:25,261 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 14:48:25,464 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:48:25] "GET / HTTP/1.1" 200 -
2024-12-25 14:48:25,871 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:48:25] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 14:48:25,903 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:48:25] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 14:48:33,030 - __main__ - INFO - File saved successfully: 0fe0a4afda26389f75f46acba2432f8e56ce6a0830c66ad483141c01debb90bc.pdf
2024-12-25 14:48:33,038 - __main__ - INFO - Temporary file removed: 0fe0a4afda26389f75f46acba2432f8e56ce6a0830c66ad483141c01debb90bc.pdf
2024-12-25 14:48:33,038 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:48:33] "POST /upload HTTP/1.1" 200 -
2024-12-25 14:48:40,651 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:48:40] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:48:40,651 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:48:40] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:48:53,624 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.07).
2024-12-25 14:48:53,632 - __main__ - WARNING - Hallucinated entities detected: {'one'}
2024-12-25 14:48:53,640 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:48:53] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:49:26,747 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 14:49:27,701 - werkzeug - INFO -  * Restarting with stat
2024-12-25 14:49:42,198 - __main__ - INFO - Successfully loaded QA model
2024-12-25 14:49:42,206 - __main__ - INFO - Starting application...
2024-12-25 14:49:42,206 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 14:49:42,206 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 14:49:42,214 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 14:49:42,254 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 14:49:42,264 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 14:49:42,402 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /ask
2024-12-25 14:49:42,402 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /ask
2024-12-25 14:49:42,410 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:49:42] "[31m[1mPOST /ask HTTP/1.1[0m" 403 -
2024-12-25 14:49:42,418 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:49:42] "[31m[1mPOST /ask HTTP/1.1[0m" 403 -
2024-12-25 14:49:53,769 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /upload
2024-12-25 14:49:53,776 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:49:53] "[31m[1mPOST /upload HTTP/1.1[0m" 403 -
2024-12-25 14:49:55,985 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:49:55] "GET / HTTP/1.1" 200 -
2024-12-25 14:49:56,260 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:49:56] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 14:49:56,303 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:49:56] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 14:50:02,596 - __main__ - INFO - File saved successfully: 4e2169daac2f80d3c75786635a391eb004e4f3f6bb4834f37f3902340fc12985.pdf
2024-12-25 14:50:02,620 - __main__ - INFO - Temporary file removed: 4e2169daac2f80d3c75786635a391eb004e4f3f6bb4834f37f3902340fc12985.pdf
2024-12-25 14:50:02,623 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:50:02] "POST /upload HTTP/1.1" 200 -
2024-12-25 14:50:14,682 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.08).
2024-12-25 14:50:14,756 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:50:14] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:50:29,374 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.15).
2024-12-25 14:50:29,399 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:50:29] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:51:09,363 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 14:51:10,363 - werkzeug - INFO -  * Restarting with stat
2024-12-25 14:51:29,392 - __main__ - INFO - Successfully loaded QA model
2024-12-25 14:51:29,398 - __main__ - INFO - Starting application...
2024-12-25 14:51:29,403 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 14:51:29,403 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 14:51:29,403 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 14:51:29,425 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 14:51:29,441 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 14:51:29,579 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:51:29] "GET / HTTP/1.1" 200 -
2024-12-25 14:51:29,921 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:51:29] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 14:51:29,929 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:51:29] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 14:52:01,029 - __main__ - INFO - File saved successfully: 5ece430ec34a1ced3377d5e6c765550b540218304d11931fc0d91862f328e5ae.pdf
2024-12-25 14:52:01,053 - __main__ - INFO - Temporary file removed: 5ece430ec34a1ced3377d5e6c765550b540218304d11931fc0d91862f328e5ae.pdf
2024-12-25 14:52:01,053 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:52:01] "POST /upload HTTP/1.1" 200 -
2024-12-25 14:52:11,485 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.08).
2024-12-25 14:52:11,501 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:52:11] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:52:22,696 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.15).
2024-12-25 14:52:22,718 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:52:22] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:52:38,286 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 14:52:38,929 - werkzeug - INFO -  * Restarting with stat
2024-12-25 14:52:56,883 - __main__ - INFO - Successfully loaded QA model
2024-12-25 14:52:56,891 - __main__ - INFO - Starting application...
2024-12-25 14:52:56,891 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 14:52:56,891 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 14:52:56,891 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 14:52:56,918 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 14:52:56,932 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 14:52:57,123 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:52:57] "GET / HTTP/1.1" 200 -
2024-12-25 14:52:57,509 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:52:57] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 14:52:57,536 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:52:57] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 14:53:07,363 - __main__ - INFO - File saved successfully: c490f702e9f550855b9c30f5103c6dba0e76a136b3909e8b4de0c0dcf02c5191.pdf
2024-12-25 14:53:07,384 - __main__ - INFO - Temporary file removed: c490f702e9f550855b9c30f5103c6dba0e76a136b3909e8b4de0c0dcf02c5191.pdf
2024-12-25 14:53:07,384 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:07] "POST /upload HTTP/1.1" 200 -
2024-12-25 14:53:17,379 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:17] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:53:17,459 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:17] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:53:18,614 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:18] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:53:18,670 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:18] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:53:24,340 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.08).
2024-12-25 14:53:24,361 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:24] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:53:24,385 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.08).
2024-12-25 14:53:24,418 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:24] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:53:38,512 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:38] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:53:38,553 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:38] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:53:51,289 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:51] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:53:51,371 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:53:51] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:56:54,455 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 14:56:55,412 - werkzeug - INFO -  * Restarting with stat
2024-12-25 14:57:14,934 - __main__ - INFO - Successfully loaded QA model
2024-12-25 14:57:14,938 - __main__ - INFO - Starting application...
2024-12-25 14:57:14,938 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 14:57:14,938 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 14:57:14,938 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 14:57:14,971 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 14:57:14,987 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 14:57:15,132 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:57:15] "GET / HTTP/1.1" 200 -
2024-12-25 14:57:15,456 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:57:15] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 14:57:15,458 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:57:15] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 14:57:31,061 - __main__ - INFO - File saved successfully: 8bb9f96db248a8fd25315ffb6843733b8afb41eea97d274eda42e70894d233a5.pdf
2024-12-25 14:57:31,085 - __main__ - INFO - Temporary file removed: 8bb9f96db248a8fd25315ffb6843733b8afb41eea97d274eda42e70894d233a5.pdf
2024-12-25 14:57:31,090 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:57:31] "POST /upload HTTP/1.1" 200 -
2024-12-25 14:57:40,545 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:57:40] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:57:40,586 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:57:40] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:58:17,088 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 14:58:18,036 - werkzeug - INFO -  * Restarting with stat
2024-12-25 14:58:35,475 - __main__ - INFO - Successfully loaded QA model
2024-12-25 14:58:35,483 - __main__ - INFO - Starting application...
2024-12-25 14:58:35,489 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 14:58:35,493 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 14:58:35,493 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 14:58:35,516 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 14:58:35,532 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 14:58:35,671 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:58:35] "GET / HTTP/1.1" 200 -
2024-12-25 14:58:36,003 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:58:36] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 14:58:36,043 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:58:36] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 14:58:48,170 - __main__ - INFO - File saved successfully: 9390d7f5faf7557362f366998264a9a3b81fcb37c92d3315972e380f3978572b.pdf
2024-12-25 14:58:48,182 - __main__ - INFO - Temporary file removed: 9390d7f5faf7557362f366998264a9a3b81fcb37c92d3315972e380f3978572b.pdf
2024-12-25 14:58:48,182 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:58:48] "POST /upload HTTP/1.1" 200 -
2024-12-25 14:58:57,006 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.02).
2024-12-25 14:58:57,037 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.02).
2024-12-25 14:58:57,046 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:58:57] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:58:57,080 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:58:57] "POST /ask HTTP/1.1" 200 -
2024-12-25 14:59:11,507 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 14:59:11] "POST /ask HTTP/1.1" 200 -
2024-12-25 15:14:52,128 - __main__ - INFO - Successfully loaded QA model
2024-12-25 15:14:52,134 - __main__ - INFO - Starting application...
2024-12-25 15:14:52,134 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 15:14:52,134 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 15:14:52,134 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 15:14:52,150 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 15:14:52,150 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 15:14:52,150 - werkzeug - INFO -  * Restarting with stat
2024-12-25 15:15:09,286 - __main__ - INFO - Successfully loaded QA model
2024-12-25 15:15:09,286 - __main__ - INFO - Starting application...
2024-12-25 15:15:09,295 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 15:15:09,296 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 15:15:09,297 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 15:15:09,314 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 15:15:09,319 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 15:15:09,523 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 15:15:09] "GET / HTTP/1.1" 200 -
2024-12-25 15:15:09,808 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 15:15:09] "GET /static/css/style.css HTTP/1.1" 200 -
2024-12-25 15:15:09,840 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 15:15:09] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-25 15:15:36,865 - __main__ - INFO - File saved successfully: f659116e3f32d205fcd64e8c0a19bf51eeebeb613ce83e8a2d315ce56ffc6e6d.pdf
2024-12-25 15:15:36,889 - __main__ - INFO - Temporary file removed: f659116e3f32d205fcd64e8c0a19bf51eeebeb613ce83e8a2d315ce56ffc6e6d.pdf
2024-12-25 15:15:36,890 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 15:15:36] "POST /upload HTTP/1.1" 200 -
2024-12-25 15:15:53,523 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.08).
2024-12-25 15:15:53,529 - __main__ - WARNING - Warning: The answer may be inconsistent with the supporting text (Similarity Score: 0.08).
2024-12-25 15:15:53,564 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 15:15:53] "POST /ask HTTP/1.1" 200 -
2024-12-25 15:15:53,564 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 15:15:53] "POST /ask HTTP/1.1" 200 -
2024-12-25 15:16:08,686 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 15:16:08] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:11:03,080 - __main__ - INFO - Successfully loaded summarization model
2024-12-25 19:11:03,089 - __main__ - INFO - Starting application...
2024-12-25 19:11:03,089 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 19:11:03,089 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 19:11:03,090 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 19:11:03,157 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 19:11:03,158 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 19:11:03,163 - werkzeug - INFO -  * Restarting with stat
2024-12-25 19:11:25,169 - __main__ - INFO - Successfully loaded summarization model
2024-12-25 19:11:25,171 - __main__ - INFO - Starting application...
2024-12-25 19:11:25,171 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 19:11:25,172 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 19:11:25,172 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 19:11:25,180 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 19:11:25,187 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 19:11:25,273 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:11:25] "GET / HTTP/1.1" 200 -
2024-12-25 19:11:25,502 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:11:25] "GET /static/css/style.css HTTP/1.1" 200 -
2024-12-25 19:11:25,503 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:11:25] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-25 19:11:34,781 - __main__ - INFO - File saved successfully: ee6333e18c8005f5adfaaa455fb4c8f62f402c955f3810608d554a61a124f833.pdf
2024-12-25 19:11:34,821 - __main__ - INFO - Temporary file removed: ee6333e18c8005f5adfaaa455fb4c8f62f402c955f3810608d554a61a124f833.pdf
2024-12-25 19:11:34,821 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:11:34] "POST /upload HTTP/1.1" 200 -
2024-12-25 19:11:46,578 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:11:46] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:11:57,165 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:11:57] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:11:57,183 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:11:57] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:12:32,200 - __main__ - INFO - File saved successfully: c81e30e6d0e6bf43308b10cc8f292582f495e0f23ac130ca26a7a96ae50afd52.pdf
2024-12-25 19:12:32,205 - __main__ - INFO - Temporary file removed: c81e30e6d0e6bf43308b10cc8f292582f495e0f23ac130ca26a7a96ae50afd52.pdf
2024-12-25 19:12:32,206 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:12:32] "POST /upload HTTP/1.1" 200 -
2024-12-25 19:12:33,758 - __main__ - INFO - File saved successfully: 29663f1e767aba98faccf0665235b9ca64ee266cf5781899c2baea439ac1e759.pdf
2024-12-25 19:12:33,768 - __main__ - INFO - Temporary file removed: 29663f1e767aba98faccf0665235b9ca64ee266cf5781899c2baea439ac1e759.pdf
2024-12-25 19:12:33,768 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:12:33] "POST /upload HTTP/1.1" 200 -
2024-12-25 19:12:45,130 - __main__ - INFO - File saved successfully: 4c7b8b014fae8208d1ef9051e157de1c1f03baf1ef167e9dab4853f17c81b1ab.pdf
2024-12-25 19:12:45,295 - __main__ - INFO - Temporary file removed: 4c7b8b014fae8208d1ef9051e157de1c1f03baf1ef167e9dab4853f17c81b1ab.pdf
2024-12-25 19:12:45,296 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:12:45] "POST /upload HTTP/1.1" 200 -
2024-12-25 19:13:03,684 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:13:03] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:13:03,702 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:13:03] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:13:31,982 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:13:31] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:13:32,020 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:13:32] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:13:48,122 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:13:48] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:13:48,231 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:13:48] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:14:02,733 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:14:02] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:14:02,734 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:14:02] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:14:24,132 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:14:24] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:25:13,704 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 19:25:16,818 - werkzeug - INFO -  * Restarting with stat
2024-12-25 19:26:42,050 - __main__ - INFO - Successfully loaded QA model
2024-12-25 19:26:42,051 - __main__ - INFO - Starting application...
2024-12-25 19:26:42,051 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 19:26:42,051 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 19:26:42,051 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 19:26:42,057 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 19:26:42,059 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 19:27:13,543 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:27:13] "[33mGET / HTTP/1.1[0m" 404 -
2024-12-25 19:27:31,442 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:27:31] "[33mGET / HTTP/1.1[0m" 404 -
2024-12-25 19:27:33,067 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:27:33] "[33mGET / HTTP/1.1[0m" 404 -
2024-12-25 19:28:59,655 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 19:29:00,418 - werkzeug - INFO -  * Restarting with stat
2024-12-25 19:29:14,983 - __main__ - INFO - Successfully loaded summarization model
2024-12-25 19:29:15,004 - __main__ - INFO - Starting application...
2024-12-25 19:29:15,004 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 19:29:15,005 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 19:29:15,005 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 19:29:15,093 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 19:29:15,106 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 19:29:20,892 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:29:20] "GET / HTTP/1.1" 200 -
2024-12-25 19:29:21,116 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:29:21] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 19:29:21,117 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:29:21] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-25 19:29:28,188 - __main__ - INFO - File saved successfully: cb39e94ca871a4a13127626972535d0199b1aeda63ba0fafb660a926b4b8e540.pdf
2024-12-25 19:29:28,232 - __main__ - INFO - Temporary file removed: cb39e94ca871a4a13127626972535d0199b1aeda63ba0fafb660a926b4b8e540.pdf
2024-12-25 19:29:28,234 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:29:28] "POST /upload HTTP/1.1" 200 -
2024-12-25 19:29:56,924 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:29:56] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:29:57,332 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:29:57] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:30:36,197 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:30:36] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:30:36,632 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:30:36] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:32:10,918 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 19:32:12,643 - werkzeug - INFO -  * Restarting with stat
2024-12-25 19:32:23,482 - __main__ - INFO - Successfully loaded QA model
2024-12-25 19:32:23,485 - __main__ - INFO - Starting application...
2024-12-25 19:32:23,485 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 19:32:23,487 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 19:32:23,487 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 19:32:23,497 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 19:32:23,500 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 19:32:35,624 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:32:35] "GET / HTTP/1.1" 200 -
2024-12-25 19:32:35,734 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:32:35] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 19:32:35,734 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:32:35] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 19:32:42,246 - __main__ - INFO - File saved successfully: 3e3c5177e97e3504f8252503eb8568a6cb885e2b1f1bd6810614c5c4c9799df2.pdf
2024-12-25 19:32:42,268 - __main__ - INFO - Temporary file removed: 3e3c5177e97e3504f8252503eb8568a6cb885e2b1f1bd6810614c5c4c9799df2.pdf
2024-12-25 19:32:42,269 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:32:42] "POST /upload HTTP/1.1" 200 -
2024-12-25 19:32:46,556 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:32:46] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:32:46,557 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:32:46] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:32:56,382 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:32:56] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:32:56,383 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:32:56] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:33:03,398 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:33:03] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:33:03,402 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:33:03] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:33:09,906 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:33:09] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:33:09,912 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:33:09] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:33:24,736 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:33:24] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:33:24,739 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:33:24] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:33:35,148 - __main__ - INFO - File saved successfully: ce6d9d770bbb2f8061b79a84144e96a4fae24ed6230ee9c146765111b91ad857.pdf
2024-12-25 19:33:35,918 - __main__ - INFO - Temporary file removed: ce6d9d770bbb2f8061b79a84144e96a4fae24ed6230ee9c146765111b91ad857.pdf
2024-12-25 19:33:35,921 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:33:35] "POST /upload HTTP/1.1" 200 -
2024-12-25 19:33:58,270 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:33:58] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:33:58,422 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:33:58] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:34:09,328 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:34:09] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:34:09,376 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:34:09] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:34:38,067 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:34:38] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:34:38,103 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:34:38] "POST /ask HTTP/1.1" 200 -
2024-12-25 19:37:05,437 - __main__ - INFO - Starting application...
2024-12-25 19:37:05,437 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 19:37:05,438 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 19:37:05,438 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 19:37:05,537 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 19:37:05,538 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 19:37:05,540 - werkzeug - INFO -  * Restarting with stat
2024-12-25 19:37:06,241 - __main__ - INFO - Starting application...
2024-12-25 19:37:06,241 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 19:37:06,242 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 19:37:06,242 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 19:37:06,249 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 19:37:06,250 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 19:37:09,761 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:37:09] "GET / HTTP/1.1" 200 -
2024-12-25 19:37:09,824 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:37:09] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 19:37:09,824 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:37:09] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 19:37:14,483 - __main__ - INFO - File saved successfully: ebbdb0a83a022b99fed48a83823bbbfeb723bfef7c7cbf481f4a82bb0a989bbd.pdf
2024-12-25 19:37:14,503 - __main__ - INFO - Temporary file removed: ebbdb0a83a022b99fed48a83823bbbfeb723bfef7c7cbf481f4a82bb0a989bbd.pdf
2024-12-25 19:37:14,504 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:37:14] "POST /upload HTTP/1.1" 200 -
2024-12-25 19:37:23,073 - __main__ - ERROR - Model error: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/question-answering (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000244BF1058B0>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))
2024-12-25 19:37:23,074 - __main__ - ERROR - Model error: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/question-answering (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000244BF104B30>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))
2024-12-25 19:37:23,076 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:37:23] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-25 19:37:23,078 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 19:37:23] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-25 19:42:13,246 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 19:42:13,391 - werkzeug - INFO -  * Restarting with stat
2024-12-25 19:56:44,717 - __main__ - INFO - Starting application...
2024-12-25 19:56:44,719 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 19:56:44,719 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 19:56:44,719 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 19:56:46,760 - __main__ - WARNING - Ollama service is not available. Please ensure Ollama is running and the mistral model is installed.
2024-12-25 19:56:46,760 - __main__ - INFO - To install Ollama, visit: https://ollama.ai/download
2024-12-25 19:56:46,760 - __main__ - INFO - After installation, run: 'ollama pull mistral' to download the required model
2024-12-25 19:56:46,783 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 19:56:46,783 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 19:56:46,786 - werkzeug - INFO -  * Restarting with stat
2024-12-25 19:57:03,431 - __main__ - INFO - Starting application...
2024-12-25 19:57:03,432 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 19:57:03,432 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 19:57:03,432 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 19:57:05,460 - __main__ - WARNING - Ollama service is not available. Please ensure Ollama is running and the mistral model is installed.
2024-12-25 19:57:05,460 - __main__ - INFO - To install Ollama, visit: https://ollama.ai/download
2024-12-25 19:57:05,460 - __main__ - INFO - After installation, run: 'ollama pull mistral' to download the required model
2024-12-25 19:57:05,466 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 19:57:05,466 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 19:59:21,677 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 19:59:22,727 - werkzeug - INFO -  * Restarting with stat
2024-12-25 19:59:37,306 - __main__ - INFO - Starting application...
2024-12-25 19:59:39,351 - __main__ - WARNING - Ollama service issue: Mistral model not found. Please run 'ollama pull mistral'
2024-12-25 19:59:39,351 - __main__ - INFO - To install Ollama, visit: https://ollama.ai/download
2024-12-25 19:59:39,351 - __main__ - INFO - After installation, run: 'ollama pull mistral' to download the required model
2024-12-25 19:59:39,352 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 19:59:39,352 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 19:59:39,352 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 19:59:39,357 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 19:59:39,360 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 20:09:35,699 - __main__ - INFO - Starting application...
2024-12-25 20:09:37,743 - __main__ - WARNING - Ollama service issue: Mistral model not found. Please run 'ollama pull mistral'
2024-12-25 20:09:37,744 - __main__ - INFO - To install Ollama, visit: https://ollama.ai/download
2024-12-25 20:09:37,744 - __main__ - INFO - After installation, run: 'ollama pull mistral' to download the required model
2024-12-25 20:09:37,744 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 20:09:37,744 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 20:09:37,744 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 20:09:37,769 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 20:09:37,769 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 20:09:37,773 - werkzeug - INFO -  * Restarting with stat
2024-12-25 20:09:55,816 - __main__ - INFO - Starting application...
2024-12-25 20:09:57,867 - __main__ - WARNING - Ollama service issue: Mistral model not found. Please run 'ollama pull mistral'
2024-12-25 20:09:57,868 - __main__ - INFO - To install Ollama, visit: https://ollama.ai/download
2024-12-25 20:09:57,868 - __main__ - INFO - After installation, run: 'ollama pull mistral' to download the required model
2024-12-25 20:09:57,868 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 20:09:57,868 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 20:09:57,869 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 20:09:57,874 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 20:09:57,886 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 20:09:57,985 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:09:57] "GET / HTTP/1.1" 200 -
2024-12-25 20:09:58,264 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:09:58] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 20:09:58,270 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:09:58] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 20:10:04,553 - __main__ - INFO - File saved successfully: 09f8d861b8e76f6d19d1ae6427448c855788b07b204aec62c38a4c9363824677.pdf
2024-12-25 20:10:04,567 - __main__ - INFO - Temporary file removed: 09f8d861b8e76f6d19d1ae6427448c855788b07b204aec62c38a4c9363824677.pdf
2024-12-25 20:10:04,567 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:10:04] "POST /upload HTTP/1.1" 200 -
2024-12-25 20:10:12,654 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:10:12] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:10:12,656 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:10:12] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:14:01,954 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 20:14:04,855 - werkzeug - INFO -  * Restarting with stat
2024-12-25 20:14:20,157 - __main__ - INFO - Starting application...
2024-12-25 20:14:20,157 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:14:32,198 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:14:32,220 - __main__ - WARNING - Ollama service issue: Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:14:32,222 - __main__ - INFO - To install Ollama, visit: https://ollama.ai/download
2024-12-25 20:14:32,223 - __main__ - INFO - After installation, run: 'ollama pull mistral' to download the required model
2024-12-25 20:14:32,224 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 20:14:32,225 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 20:14:32,225 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 20:14:32,263 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 20:14:32,283 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 20:16:06,168 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 20:16:08,034 - werkzeug - INFO -  * Restarting with stat
2024-12-25 20:16:23,904 - __main__ - INFO - Starting application...
2024-12-25 20:16:23,904 - __main__ - INFO - Verifying Ollama setup...
2024-12-25 20:16:26,011 - __main__ - INFO - Ollama service status: 200
2024-12-25 20:16:26,012 - __main__ - INFO - Available models: [{'name': 'mistral:latest', 'model': 'mistral:latest', 'modified_at': '2024-12-25T20:10:29.7226198+05:30', 'size': 4113301824, 'digest': 'f974a74358d62a017b37c6f424fcdf2744ca02926c4f952513ddf474b2fa5091', 'details': {'parent_model': '', 'format': 'gguf', 'family': 'llama', 'families': ['llama'], 'parameter_size': '7.2B', 'quantization_level': 'Q4_0'}}]
2024-12-25 20:16:55,383 - __main__ - INFO - Successfully tested Mistral model
2024-12-25 20:16:55,398 - __main__ - INFO - Ollama setup verified successfully
2024-12-25 20:16:55,399 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 20:16:55,402 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 20:16:55,402 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 20:16:55,496 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 20:16:55,532 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 20:16:55,983 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:16:55] "GET / HTTP/1.1" 200 -
2024-12-25 20:16:56,409 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:16:56] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 20:16:56,411 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:16:56] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 20:17:05,582 - __main__ - INFO - File saved successfully: d5b8cedc4743ef4a69ee918ce29f09a40be1f6762b018af9fe767517a6f87cbe.pdf
2024-12-25 20:17:05,645 - __main__ - INFO - Temporary file removed: d5b8cedc4743ef4a69ee918ce29f09a40be1f6762b018af9fe767517a6f87cbe.pdf
2024-12-25 20:17:05,645 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:17:05] "POST /upload HTTP/1.1" 200 -
2024-12-25 20:17:11,304 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:17:11,321 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:17:23,425 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:17:23,426 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:17:23,427 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:17:23] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:17:23,427 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:17:23] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:17:43,929 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:17:43,932 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:17:54,624 - __main__ - INFO - Health check response status: 200
2024-12-25 20:17:54,624 - __main__ - INFO - Ollama is healthy and responding
2024-12-25 20:17:54,947 - __main__ - INFO - Attempting to connect to Ollama...
2024-12-25 20:17:55,974 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:17:55,976 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:17:55] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:18:03,164 - __main__ - INFO - Ollama response status: 200
2024-12-25 20:18:03,164 - __main__ - INFO - Successfully received response from Ollama
2024-12-25 20:18:04,586 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:18:04] "POST /ask HTTP/1.1" 200 -
2024-12-25 20:18:20,522 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:18:20,522 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:18:30,134 - __main__ - INFO - Health check response status: 200
2024-12-25 20:18:30,134 - __main__ - INFO - Ollama is healthy and responding
2024-12-25 20:18:30,162 - __main__ - INFO - Attempting to connect to Ollama...
2024-12-25 20:18:30,504 - __main__ - INFO - Health check response status: 200
2024-12-25 20:18:30,504 - __main__ - INFO - Ollama is healthy and responding
2024-12-25 20:18:30,533 - __main__ - INFO - Attempting to connect to Ollama...
2024-12-25 20:18:48,284 - __main__ - INFO - Ollama response status: 200
2024-12-25 20:18:48,285 - __main__ - INFO - Ollama response status: 200
2024-12-25 20:18:48,285 - __main__ - INFO - Successfully received response from Ollama
2024-12-25 20:18:48,286 - __main__ - INFO - Successfully received response from Ollama
2024-12-25 20:18:48,367 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:18:48] "POST /ask HTTP/1.1" 200 -
2024-12-25 20:18:48,367 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:18:48] "POST /ask HTTP/1.1" 200 -
2024-12-25 20:19:35,082 - __main__ - INFO - File saved successfully: 3465e714435591f0a75a91cdf852458536bf8a68c8217e416ccc2a34bef0722a.pdf
2024-12-25 20:19:35,305 - __main__ - INFO - Temporary file removed: 3465e714435591f0a75a91cdf852458536bf8a68c8217e416ccc2a34bef0722a.pdf
2024-12-25 20:19:35,305 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:19:35] "POST /upload HTTP/1.1" 200 -
2024-12-25 20:20:03,578 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:20:15,620 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:20:15,624 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:20:15] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:20:46,369 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:20:46,371 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:20:58,422 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:20:58,424 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:20:58] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:20:58,438 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:20:58,440 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:20:58] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:21:19,713 - __main__ - INFO - File saved successfully: 5d34298bfb6362a43f4318dd3f782744adff37aa37737deaa3759785a4fbb33f.pdf
2024-12-25 20:21:19,743 - __main__ - INFO - Temporary file removed: 5d34298bfb6362a43f4318dd3f782744adff37aa37737deaa3759785a4fbb33f.pdf
2024-12-25 20:21:19,745 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:21:19] "POST /upload HTTP/1.1" 200 -
2024-12-25 20:21:22,659 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:21:34,680 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:21:34,683 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:21:34] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:21:49,415 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:21:49,422 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:22:00,383 - __main__ - INFO - Health check response status: 200
2024-12-25 20:22:00,383 - __main__ - INFO - Ollama is healthy and responding
2024-12-25 20:22:00,566 - __main__ - INFO - Attempting to connect to Ollama...
2024-12-25 20:22:01,469 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:22:01,470 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:22:01] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:22:11,282 - __main__ - INFO - Ollama response status: 200
2024-12-25 20:22:11,285 - __main__ - INFO - Successfully received response from Ollama
2024-12-25 20:22:11,852 - __main__ - WARNING - Hallucinated entities detected: {'France'}
2024-12-25 20:22:11,854 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:22:11] "POST /ask HTTP/1.1" 200 -
2024-12-25 20:22:37,496 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:22:37,498 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:22:47,903 - __main__ - INFO - Health check response status: 200
2024-12-25 20:22:47,903 - __main__ - INFO - Ollama is healthy and responding
2024-12-25 20:22:47,940 - __main__ - INFO - Attempting to connect to Ollama...
2024-12-25 20:22:49,577 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:22:49,578 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:22:49] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:22:58,447 - __main__ - INFO - Ollama response status: 200
2024-12-25 20:22:58,447 - __main__ - INFO - Successfully received response from Ollama
2024-12-25 20:22:58,603 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:22:58] "POST /ask HTTP/1.1" 200 -
2024-12-25 20:23:27,722 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:23:27,734 - __main__ - INFO - Checking Ollama health...
2024-12-25 20:23:39,767 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:23:39,773 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:23:39] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:23:39,783 - __main__ - ERROR - Unexpected error checking Ollama health: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=10)
2024-12-25 20:23:39,811 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 20:23:39] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 20:45:57,493 - __main__ - INFO - Loading NLP models...
2024-12-25 20:45:57,979 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 20:45:57,979 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2024-12-25 20:46:01,303 - __main__ - INFO - NLP models loaded successfully
2024-12-25 20:46:01,344 - __main__ - INFO - Starting application...
2024-12-25 20:46:01,344 - __main__ - INFO - Warming up Ollama...
2024-12-25 20:46:01,344 - __main__ - INFO - Sending request to Ollama...
2024-12-25 20:46:33,452 - __main__ - ERROR - Ollama request timed out
2024-12-25 20:46:34,476 - __main__ - INFO - Sending request to Ollama...
2024-12-25 20:47:06,640 - __main__ - ERROR - Ollama request timed out
2024-12-25 20:47:08,646 - __main__ - INFO - Sending request to Ollama...
2024-12-25 20:47:15,313 - __main__ - ERROR - Connection to Ollama failed
2024-12-25 20:47:18,314 - __main__ - INFO - Ollama warmup completed
2024-12-25 20:47:18,316 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 20:47:18,320 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 20:47:18,320 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 20:47:18,713 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 20:47:18,713 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 20:47:18,730 - werkzeug - INFO -  * Restarting with stat
2024-12-25 20:47:30,435 - __main__ - INFO - Loading NLP models...
2024-12-25 20:47:31,080 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 20:47:31,080 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2024-12-25 20:47:34,590 - __main__ - INFO - NLP models loaded successfully
2024-12-25 20:47:34,602 - __main__ - INFO - Starting application...
2024-12-25 20:47:34,602 - __main__ - INFO - Warming up Ollama...
2024-12-25 20:47:34,604 - __main__ - INFO - Sending request to Ollama...
2024-12-25 20:51:18,494 - __main__ - INFO - Loading NLP models...
2024-12-25 20:51:18,997 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 20:51:18,997 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2024-12-25 20:51:23,785 - __main__ - INFO - NLP models loaded successfully
2024-12-25 20:51:23,792 - __main__ - INFO - Starting application...
2024-12-25 20:51:23,792 - __main__ - INFO - Warming up Ollama...
2024-12-25 20:51:23,792 - __main__ - INFO - Sending request to Ollama...
2024-12-25 20:51:53,809 - __main__ - ERROR - Ollama request timed out
2024-12-25 20:51:54,823 - __main__ - INFO - Sending request to Ollama...
2024-12-25 20:52:24,856 - __main__ - ERROR - Ollama request timed out
2024-12-25 20:52:26,858 - __main__ - INFO - Sending request to Ollama...
2024-12-25 20:52:56,883 - __main__ - ERROR - Ollama request timed out
2024-12-25 20:52:59,886 - __main__ - INFO - Ollama warmup completed
2024-12-25 20:52:59,889 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 20:52:59,891 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 20:52:59,891 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 20:53:00,150 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 20:53:00,150 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 20:53:00,166 - werkzeug - INFO -  * Restarting with stat
2024-12-25 20:53:12,447 - __main__ - INFO - Loading NLP models...
2024-12-25 20:53:13,169 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 20:53:13,169 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2024-12-25 20:53:17,726 - __main__ - INFO - NLP models loaded successfully
2024-12-25 20:53:17,751 - __main__ - INFO - Starting application...
2024-12-25 20:53:17,753 - __main__ - INFO - Warming up Ollama...
2024-12-25 20:53:17,753 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:00:18,588 - __main__ - INFO - Loading NLP models...
2024-12-25 21:00:19,230 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 21:00:19,230 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2024-12-25 21:00:23,862 - __main__ - INFO - NLP models loaded successfully
2024-12-25 21:00:23,871 - __main__ - INFO - Starting application...
2024-12-25 21:00:23,871 - __main__ - INFO - Warming up Ollama...
2024-12-25 21:00:23,871 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:00:26,813 - __main__ - INFO - Ollama warmup completed successfully
2024-12-25 21:00:26,814 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:00:26,814 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:00:26,814 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:00:26,834 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 21:00:26,839 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 21:00:26,841 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:00:34,654 - __main__ - INFO - Loading NLP models...
2024-12-25 21:00:35,134 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 21:00:35,134 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2024-12-25 21:00:39,254 - __main__ - INFO - NLP models loaded successfully
2024-12-25 21:00:39,266 - __main__ - INFO - Starting application...
2024-12-25 21:00:39,266 - __main__ - INFO - Warming up Ollama...
2024-12-25 21:00:39,266 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:00:46,381 - __main__ - INFO - Ollama warmup completed successfully
2024-12-25 21:00:46,381 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:00:46,384 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:00:46,384 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:00:46,385 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:00:46,394 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:00:46,454 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:00:46] "GET / HTTP/1.1" 200 -
2024-12-25 21:00:46,610 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:00:46] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 21:00:46,614 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:00:46] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 21:00:58,785 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:00:58] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:01:03,194 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:01:03,195 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:01:14,148 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:01:14] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:01:14,148 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:01:14] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:01:15,027 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:01:17,167 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:01:30,039 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:01:30,541 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:01:32,175 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:01:32,677 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:01:35,154 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:01:35,194 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:01:42,698 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:01:42] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:01:44,716 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:01:44] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:01:45,559 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:01:46,560 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:01:47,704 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:01:48,705 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:01:56,190 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:01:56] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:02:01,572 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:02:03,075 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:02:03] "[35m[1mGET /test-ollama HTTP/1.1[0m" 500 -
2024-12-25 21:02:03,709 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:02:05,211 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:02:05] "[35m[1mGET /test-ollama HTTP/1.1[0m" 500 -
2024-12-25 21:02:06,150 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:02:06] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-12-25 21:02:09,351 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:02:09,366 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:02:24,364 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:02:24,372 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:02:24,865 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:02:24,874 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:02:39,871 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:02:39,895 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:02:40,872 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:02:40,896 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:02:55,882 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:02:55,914 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:02:57,391 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:02:57] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:02:57,417 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:02:57] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:04:47,655 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 21:04:49,288 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:04:57,157 - __main__ - INFO - Loading NLP models...
2024-12-25 21:04:57,577 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 21:04:57,577 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2024-12-25 21:05:01,312 - __main__ - INFO - NLP models loaded successfully
2024-12-25 21:05:01,321 - __main__ - INFO - Starting application...
2024-12-25 21:05:01,321 - __main__ - INFO - Warming up Ollama...
2024-12-25 21:05:01,321 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:05:16,342 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:05:16,856 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:05:31,927 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:05:32,928 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:05:47,937 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:05:49,438 - __main__ - INFO - Ollama warmup completed successfully
2024-12-25 21:05:49,440 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:05:49,442 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:05:49,443 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:05:49,564 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:05:49,605 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:06:30,959 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:06:30] "GET / HTTP/1.1" 200 -
2024-12-25 21:06:31,682 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:06:31] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 21:06:31,684 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:06:31] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 21:06:43,795 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:06:43] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:06:53,591 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:06:53,594 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:07:08,607 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:07:08,608 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:07:09,109 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:07:09,109 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:07:24,114 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:07:24,115 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:07:25,116 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:07:25,116 - __main__ - INFO - Sending request to Ollama...
2024-12-25 21:07:40,118 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:07:40,119 - __main__ - ERROR - Ollama request timed out
2024-12-25 21:07:41,629 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:07:41] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:07:41,630 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:07:41] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:09:01,879 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 21:09:05,614 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:09:19,255 - __main__ - INFO - Loading NLP models...
2024-12-25 21:09:19,877 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 21:09:19,881 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2024-12-25 21:09:23,414 - __main__ - INFO - NLP models loaded successfully
2024-12-25 21:09:23,426 - __main__ - INFO - Starting application...
2024-12-25 21:09:23,426 - __main__ - INFO - Warming up Ollama...
2024-12-25 21:09:28,875 - __main__ - INFO - Ollama warmup completed successfully
2024-12-25 21:09:28,875 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:09:28,876 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:09:28,876 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:09:28,884 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:09:28,890 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:09:44,946 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:09:44] "GET / HTTP/1.1" 200 -
2024-12-25 21:09:45,085 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:09:45] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 21:09:45,085 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:09:45] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 21:09:55,343 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:09:55] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:10:20,429 - __main__ - ERROR - Request timed out
2024-12-25 21:10:20,429 - __main__ - ERROR - Request timed out
2024-12-25 21:10:35,934 - __main__ - ERROR - Request timed out
2024-12-25 21:10:35,934 - __main__ - ERROR - Request timed out
2024-12-25 21:10:49,384 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:10:49] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:10:50,536 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:10:50] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:11:21,136 - __main__ - ERROR - Request timed out
2024-12-25 21:11:21,144 - __main__ - ERROR - Request timed out
2024-12-25 21:11:36,656 - __main__ - ERROR - Request timed out
2024-12-25 21:11:36,656 - __main__ - ERROR - Request timed out
2024-12-25 21:11:52,173 - __main__ - ERROR - Request timed out
2024-12-25 21:11:52,173 - __main__ - ERROR - Request timed out
2024-12-25 21:12:07,677 - __main__ - ERROR - Request timed out
2024-12-25 21:12:07,685 - __main__ - ERROR - Request timed out
2024-12-25 21:12:22,802 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:12:22] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:12:23,196 - __main__ - ERROR - Request timed out
2024-12-25 21:12:33,589 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:12:33] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:12:59,399 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:12:59] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:13:01,486 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:13:01] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:13:18,846 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:13:18] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:13:28,150 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:13:28] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:13:31,907 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:13:31] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:13:44,629 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:13:44] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:13:44,783 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:13:44] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:13:54,487 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:13:54] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:13:57,927 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:13:57] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:14:11,181 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:14:11] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:14:35,968 - __main__ - ERROR - Request timed out
2024-12-25 21:14:36,017 - __main__ - ERROR - Request timed out
2024-12-25 21:14:51,475 - __main__ - ERROR - Request timed out
2024-12-25 21:14:51,524 - __main__ - ERROR - Request timed out
2024-12-25 21:15:06,983 - __main__ - ERROR - Request timed out
2024-12-25 21:15:07,032 - __main__ - ERROR - Request timed out
2024-12-25 21:15:22,489 - __main__ - ERROR - Request timed out
2024-12-25 21:15:22,537 - __main__ - ERROR - Request timed out
2024-12-25 21:15:29,884 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 21:15:31,544 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:15:42,834 - __main__ - INFO - Loading NLP models...
2024-12-25 21:15:43,514 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 21:15:43,514 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2024-12-25 21:15:48,759 - __main__ - INFO - NLP models loaded successfully
2024-12-25 21:15:48,764 - __main__ - INFO - Starting application...
2024-12-25 21:15:48,764 - __main__ - INFO - Warming up Ollama...
2024-12-25 21:15:48,774 - __main__ - ERROR - Ollama error response: {"error":"model 'phi' not found"}
2024-12-25 21:15:49,281 - __main__ - ERROR - Ollama error response: {"error":"model 'phi' not found"}
2024-12-25 21:15:49,789 - __main__ - ERROR - Ollama error response: {"error":"model 'phi' not found"}
2024-12-25 21:15:50,291 - __main__ - INFO - Ollama warmup completed successfully
2024-12-25 21:15:50,291 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:15:50,291 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:15:50,292 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:15:50,357 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:15:50,357 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:27:15,106 - __main__ - INFO - Loading QA model...
2024-12-25 21:27:15,106 - __main__ - INFO - Initializing FastQA...
2024-12-25 21:27:25,926 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:27:25,926 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:27:25,936 - __main__ - INFO - Starting application...
2024-12-25 21:27:25,961 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 21:27:25,961 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 21:27:25,966 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:27:31,021 - __main__ - INFO - Loading QA model...
2024-12-25 21:27:31,021 - __main__ - INFO - Initializing FastQA...
2024-12-25 21:27:35,986 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:27:35,990 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:27:35,998 - __main__ - INFO - Starting application...
2024-12-25 21:27:36,018 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:27:36,030 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:27:36,408 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:27:36] "[35m[1mGET / HTTP/1.1[0m" 500 -
2024-12-25 21:27:36,764 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:27:36] "GET /?__debugger__=yes&cmd=resource&f=debugger.js HTTP/1.1" 200 -
2024-12-25 21:27:36,764 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:27:36] "GET /?__debugger__=yes&cmd=resource&f=style.css HTTP/1.1" 200 -
2024-12-25 21:27:36,922 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:27:36] "GET /?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1" 200 -
2024-12-25 21:27:36,937 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:27:36] "[36mGET /?__debugger__=yes&cmd=resource&f=console.png HTTP/1.1[0m" 304 -
2024-12-25 21:32:17,226 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 21:32:17,867 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:32:22,031 - __main__ - INFO - Loading QA model...
2024-12-25 21:32:22,031 - __main__ - INFO - Initializing FastQA...
2024-12-25 21:32:25,599 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:32:25,599 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:32:25,606 - __main__ - INFO - Starting application...
2024-12-25 21:32:25,606 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 21:32:25,606 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:32:25,606 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:32:25,606 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:32:25,618 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:32:25,622 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:32:46,767 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:32:46] "GET / HTTP/1.1" 200 -
2024-12-25 21:32:46,889 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:32:46] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 21:32:46,890 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:32:46] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 21:32:54,847 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:32:54] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:33:20,117 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:33:20] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:33:20,120 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:33:20] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:33:30,287 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:33:30] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:33:30,287 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:33:30] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:33:53,727 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:33:53] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:33:53,730 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:33:53] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:34:11,942 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:34:11] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:34:19,640 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:34:19] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:34:19,640 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:34:19] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:34:34,101 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:34:34] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:34:34,103 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:34:34] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:37:32,216 - __main__ - INFO - Loading QA model...
2024-12-25 21:37:32,216 - __main__ - INFO - Initializing FastQA...
2024-12-25 21:37:33,597 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:37:33,597 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:37:33,600 - __main__ - INFO - Starting application...
2024-12-25 21:37:33,600 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 21:37:33,600 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:37:33,607 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:37:33,607 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:37:33,618 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.16.72:5000
2024-12-25 21:37:33,627 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 21:37:33,630 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:37:40,618 - __main__ - INFO - Loading QA model...
2024-12-25 21:37:40,618 - __main__ - INFO - Initializing FastQA...
2024-12-25 21:37:42,787 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:37:42,787 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:37:42,800 - __main__ - INFO - Starting application...
2024-12-25 21:37:42,800 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 21:37:42,802 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:37:42,802 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:37:42,802 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:37:42,820 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:37:42,835 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:37:42,951 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:37:42] "GET / HTTP/1.1" 200 -
2024-12-25 21:37:43,117 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:37:43] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 21:37:43,126 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:37:43] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 21:37:49,847 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:37:49] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:37:52,997 - __main__ - ERROR - Answer generation error: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\nanda/nltk_data'
    - 'C:\\Python312\\nltk_data'
    - 'C:\\Python312\\share\\nltk_data'
    - 'C:\\Python312\\lib\\nltk_data'
    - 'C:\\Users\\nanda\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2024-12-25 21:37:52,997 - __main__ - ERROR - Answer generation error: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\nanda/nltk_data'
    - 'C:\\Python312\\nltk_data'
    - 'C:\\Python312\\share\\nltk_data'
    - 'C:\\Python312\\lib\\nltk_data'
    - 'C:\\Users\\nanda\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2024-12-25 21:37:53,007 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:37:53] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:37:53,014 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:37:53] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:38:42,557 - __main__ - INFO - Loading QA model...
2024-12-25 21:38:42,557 - __main__ - INFO - Initializing FastQA...
2024-12-25 21:38:43,993 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:38:43,993 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:38:44,001 - __main__ - INFO - Starting application...
2024-12-25 21:38:44,001 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 21:38:44,001 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:38:44,006 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:38:44,006 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:38:44,018 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.16.72:5000
2024-12-25 21:38:44,027 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 21:38:44,029 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:38:54,246 - __main__ - INFO - Loading QA model...
2024-12-25 21:38:54,247 - __main__ - INFO - Initializing FastQA...
2024-12-25 21:38:55,155 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:38:55,155 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:38:55,157 - __main__ - INFO - Starting application...
2024-12-25 21:38:55,157 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 21:38:55,157 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:38:55,157 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:38:55,157 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:38:55,169 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:38:55,174 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:38:55,227 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:38:55] "GET / HTTP/1.1" 200 -
2024-12-25 21:38:55,337 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:38:55] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 21:38:55,365 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:38:55] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 21:39:01,172 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:39:01] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:39:04,737 - __main__ - ERROR - Answer generation error: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\nanda/nltk_data'
    - 'C:\\Python312\\nltk_data'
    - 'C:\\Python312\\share\\nltk_data'
    - 'C:\\Python312\\lib\\nltk_data'
    - 'C:\\Users\\nanda\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2024-12-25 21:39:04,737 - __main__ - ERROR - Answer generation error: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\nanda/nltk_data'
    - 'C:\\Python312\\nltk_data'
    - 'C:\\Python312\\share\\nltk_data'
    - 'C:\\Python312\\lib\\nltk_data'
    - 'C:\\Users\\nanda\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2024-12-25 21:39:04,737 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:39:04] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:39:04,747 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:39:04] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:39:50,827 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 21:39:51,779 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:40:02,217 - __main__ - INFO - Loading QA model...
2024-12-25 21:40:02,217 - __main__ - INFO - Initializing FastQA...
2024-12-25 21:40:03,448 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:40:03,448 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:40:03,457 - __main__ - INFO - Starting application...
2024-12-25 21:40:03,457 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 21:40:03,457 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:40:03,457 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:40:03,464 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:40:03,477 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:40:03,483 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:40:03,570 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:40:03] "GET / HTTP/1.1" 200 -
2024-12-25 21:40:03,756 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:40:03] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 21:40:03,759 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:40:03] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 21:40:11,568 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:40:11] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:40:14,604 - __main__ - ERROR - Answer generation error: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\nanda/nltk_data'
    - 'C:\\Python312\\nltk_data'
    - 'C:\\Python312\\share\\nltk_data'
    - 'C:\\Python312\\lib\\nltk_data'
    - 'C:\\Users\\nanda\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2024-12-25 21:40:14,607 - __main__ - ERROR - Answer generation error: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\nanda/nltk_data'
    - 'C:\\Python312\\nltk_data'
    - 'C:\\Python312\\share\\nltk_data'
    - 'C:\\Python312\\lib\\nltk_data'
    - 'C:\\Users\\nanda\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2024-12-25 21:40:14,607 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:40:14] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:40:14,612 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:40:14] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:41:50,022 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 21:41:51,402 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:42:07,392 - __main__ - INFO - Loading QA model...
2024-12-25 21:42:07,392 - __main__ - INFO - Initializing FastQA...
2024-12-25 21:42:08,667 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:42:08,667 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:42:08,679 - __main__ - INFO - Starting application...
2024-12-25 21:42:08,679 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 21:42:08,679 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 21:42:08,685 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 21:42:08,687 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 21:42:08,701 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:42:08,710 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:42:08,897 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:42:08] "GET / HTTP/1.1" 200 -
2024-12-25 21:42:09,127 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:42:09] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 21:42:09,127 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:42:09] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 21:42:16,377 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:42:16] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:42:22,167 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:42:22] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:42:22,170 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:42:22] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:42:36,077 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:42:36] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:42:36,114 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:42:36] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 21:44:51,053 - __main__ - INFO - Loading QA model...
2024-12-25 21:44:51,053 - __main__ - INFO - Initializing FastQA with DistilBERT...
2024-12-25 21:44:52,027 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:44:52,027 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:44:52,037 - __main__ - INFO - Starting application...
2024-12-25 21:44:52,097 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-25 21:44:52,099 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 21:44:52,100 - werkzeug - INFO -  * Restarting with stat
2024-12-25 21:45:06,667 - __main__ - INFO - Loading QA model...
2024-12-25 21:45:06,671 - __main__ - INFO - Initializing FastQA with DistilBERT...
2024-12-25 21:45:08,127 - __main__ - INFO - FastQA initialized successfully
2024-12-25 21:45:08,127 - __main__ - INFO - QA model loaded successfully
2024-12-25 21:45:08,137 - __main__ - INFO - Starting application...
2024-12-25 21:45:08,151 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 21:45:08,159 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 21:45:08,267 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:45:08] "GET / HTTP/1.1" 200 -
2024-12-25 21:45:08,479 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:45:08] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 21:45:08,479 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:45:08] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 21:45:16,557 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:45:16] "POST /upload HTTP/1.1" 200 -
2024-12-25 21:45:28,680 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:45:28] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:45:28,680 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:45:28] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:45:46,121 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:45:46] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:45:46,127 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:45:46] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:45:53,372 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:45:53] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:45:53,442 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 21:45:53] "POST /ask HTTP/1.1" 200 -
2024-12-25 21:55:30,121 - __main__ - INFO - Loading Enhanced QA model...
2024-12-25 21:55:30,121 - __main__ - INFO - Initializing Enhanced QA System...
2024-12-25 22:00:52,178 - __main__ - INFO - Enhanced QA System initialized successfully
2024-12-25 22:00:52,206 - __main__ - INFO - Enhanced QA model loaded successfully
2024-12-25 22:00:52,268 - __main__ - INFO - Starting application...
2024-12-25 22:00:52,270 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 22:00:52,272 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 22:00:52,273 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 22:00:52,275 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 22:00:52,848 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.16.72:5000
2024-12-25 22:00:52,852 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 22:00:52,897 - werkzeug - INFO -  * Restarting with stat
2024-12-25 22:00:59,602 - __main__ - INFO - Loading Enhanced QA model...
2024-12-25 22:00:59,602 - __main__ - INFO - Initializing Enhanced QA System...
2024-12-25 22:01:14,636 - __main__ - INFO - Enhanced QA System initialized successfully
2024-12-25 22:01:14,645 - __main__ - INFO - Enhanced QA model loaded successfully
2024-12-25 22:01:14,666 - __main__ - INFO - Starting application...
2024-12-25 22:01:14,668 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 22:01:14,668 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 22:01:14,669 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 22:01:14,670 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 22:01:14,788 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 22:01:14,817 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 22:01:32,168 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:01:32] "GET / HTTP/1.1" 200 -
2024-12-25 22:01:32,317 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:01:32] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 22:01:32,319 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:01:32] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 22:01:38,997 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:01:38] "POST /upload HTTP/1.1" 200 -
2024-12-25 22:02:05,299 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:02:05] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:02:05,315 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:02:05] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:02:42,777 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:02:42] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:02:42,802 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:02:42] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:03:08,065 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:03:08] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:03:08,149 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:03:08] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:03:49,828 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:03:49] "POST /upload HTTP/1.1" 200 -
2024-12-25 22:03:59,698 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:03:59] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:03:59,705 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:03:59] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:04:11,627 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:04:11] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:04:11,629 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:04:11] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:04:19,921 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:04:19] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:04:19,937 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:04:19] "POST /ask HTTP/1.1" 200 -
2024-12-25 22:04:33,594 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:04:33] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 22:04:33,619 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:04:33] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 22:04:44,708 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:04:44] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 22:04:44,748 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:04:44] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 22:05:05,864 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:05:05] "POST /upload HTTP/1.1" 200 -
2024-12-25 22:05:08,798 - __main__ - ERROR - Summarization error: index out of range in self
2024-12-25 22:09:19,098 - werkzeug - INFO -  * Detected change in 'C:\\Users\\nanda\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-25 22:09:22,789 - werkzeug - INFO -  * Restarting with stat
2024-12-25 22:09:32,157 - __main__ - INFO - Loading Enhanced QA model...
2024-12-25 22:09:32,158 - __main__ - INFO - Initializing Enhanced QA System...
2024-12-25 22:09:33,182 - __main__ - INFO - Enhanced QA System initialized successfully
2024-12-25 22:09:33,183 - __main__ - INFO - Enhanced QA model loaded successfully
2024-12-25 22:09:33,184 - __main__ - INFO - Starting application...
2024-12-25 22:09:33,185 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 22:09:33,185 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 22:09:33,192 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 22:09:33,192 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 22:09:33,203 - werkzeug - WARNING -  * Debugger is active!
2024-12-25 22:09:33,207 - werkzeug - INFO -  * Debugger PIN: 134-061-009
2024-12-25 22:09:59,045 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:09:59] "GET / HTTP/1.1" 200 -
2024-12-25 22:09:59,207 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:09:59] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-25 22:09:59,207 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:09:59] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-25 22:10:05,436 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:10:05] "POST /upload HTTP/1.1" 200 -
2024-12-25 22:10:10,954 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:10:10] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 22:10:10,955 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:10:10] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 22:10:20,007 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:10:20] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 22:10:20,014 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:10:20] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 22:10:34,278 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:10:34] "POST /upload HTTP/1.1" 200 -
2024-12-25 22:11:29,886 - werkzeug - INFO - 127.0.0.1 - - [25/Dec/2024 22:11:29] "[35m[1mPOST /ask HTTP/1.1[0m" 503 -
2024-12-25 22:14:57,041 - __main__ - INFO - Loading DocumentQA model...
2024-12-25 22:14:57,041 - __main__ - INFO - Initializing DocumentQA with google/flan-t5-large on cpu...
2024-12-25 22:23:48,155 - __main__ - INFO - Loading RAG Document QA model...
2024-12-25 22:23:48,157 - __main__ - INFO - Initializing RAG Document QA System...
2024-12-25 22:23:48,160 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 22:23:48,160 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2024-12-25 22:28:53,119 - __main__ - INFO - RAG System initialized successfully
2024-12-25 22:28:53,121 - __main__ - INFO - RAG Document QA model loaded successfully
2024-12-25 22:28:53,127 - __main__ - INFO - Starting application...
2024-12-25 22:28:53,128 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 22:28:53,129 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 22:28:53,130 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 22:28:53,131 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 22:28:53,203 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.16.72:5000
2024-12-25 22:28:53,205 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 22:28:53,211 - werkzeug - INFO -  * Restarting with stat
2024-12-25 22:29:05,499 - __main__ - INFO - Loading RAG Document QA model...
2024-12-25 22:29:05,499 - __main__ - INFO - Initializing RAG Document QA System...
2024-12-25 22:29:05,513 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 22:29:05,513 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2024-12-25 22:33:59,779 - __main__ - INFO - Loading RAG Document QA model...
2024-12-25 22:33:59,781 - __main__ - INFO - Initializing RAG Document QA System...
2024-12-25 22:33:59,782 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 22:33:59,782 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2024-12-25 22:34:04,992 - __main__ - INFO - RAG System initialized successfully
2024-12-25 22:34:04,992 - __main__ - INFO - RAG Document QA model loaded successfully
2024-12-25 22:34:04,992 - __main__ - INFO - Starting application...
2024-12-25 22:34:04,994 - __main__ - INFO - Root directory: C:\Users\nanda\Chatbot\chatbot_system
2024-12-25 22:34:04,994 - __main__ - INFO - Template folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\templates
2024-12-25 22:34:04,994 - __main__ - INFO - Static folder: C:\Users\nanda\Chatbot\chatbot_system\frontend\static
2024-12-25 22:34:04,994 - __main__ - INFO - Upload folder: C:\Users\nanda\Chatbot\chatbot_system\temp
2024-12-25 22:34:05,028 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.16.72:5000
2024-12-25 22:34:05,028 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-25 22:34:05,031 - werkzeug - INFO -  * Restarting with stat
2024-12-25 22:34:11,914 - __main__ - INFO - Loading RAG Document QA model...
2024-12-25 22:34:11,914 - __main__ - INFO - Initializing RAG Document QA System...
2024-12-25 22:34:11,923 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-25 22:34:11,923 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2024-12-26 00:18:50,668 - __main__ - INFO - Starting application...
2024-12-26 00:18:50,669 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:18:50,669 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:18:50,669 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:18:50,696 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-26 00:18:50,698 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-26 00:18:50,700 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:18:52,164 - __main__ - INFO - Starting application...
2024-12-26 00:18:52,165 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:18:52,165 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:18:52,166 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:18:52,182 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:18:52,188 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:18:55,736 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:18:55] "GET / HTTP/1.1" 200 -
2024-12-26 00:18:55,900 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:18:55] "GET /static/css/style.css HTTP/1.1" 200 -
2024-12-26 00:18:55,904 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:18:55] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 00:19:01,625 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:19:01] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 00:19:02,420 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:19:02] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 00:19:08,347 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:19:08] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 00:19:14,962 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:19:14] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 00:23:02,388 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 00:23:02,617 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:23:53,367 - __main__ - INFO - Loading QA system...
2024-12-26 00:23:53,367 - __main__ - INFO - Initializing QA System on cpu...
2024-12-26 00:23:53,370 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-26 00:23:53,370 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2024-12-26 00:24:12,349 - __main__ - INFO - SentenceTransformer model loaded successfully.
2024-12-26 00:24:12,934 - __main__ - INFO - QA pipeline loaded successfully.
2024-12-26 00:24:12,935 - __main__ - INFO - Creating new FAISS index and initializing chunks list...
2024-12-26 00:24:12,935 - __main__ - INFO - FAISS index and chunks list initialized.
2024-12-26 00:24:12,936 - __main__ - INFO - QA system loaded successfully.
2024-12-26 00:24:12,938 - __main__ - INFO - Starting application...
2024-12-26 00:24:12,938 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:24:12,940 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:24:12,940 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:24:12,964 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.1.35:5000
2024-12-26 00:24:12,965 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-26 00:24:12,968 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:24:20,787 - __main__ - INFO - Loading QA system...
2024-12-26 00:24:20,787 - __main__ - INFO - Initializing QA System on cpu...
2024-12-26 00:24:20,790 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2024-12-26 00:24:20,790 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2024-12-26 00:24:24,602 - __main__ - INFO - SentenceTransformer model loaded successfully.
2024-12-26 00:24:25,173 - __main__ - INFO - QA pipeline loaded successfully.
2024-12-26 00:24:25,173 - __main__ - INFO - Creating new FAISS index and initializing chunks list...
2024-12-26 00:24:25,174 - __main__ - INFO - FAISS index and chunks list initialized.
2024-12-26 00:24:25,174 - __main__ - INFO - QA system loaded successfully.
2024-12-26 00:24:25,176 - __main__ - INFO - Starting application...
2024-12-26 00:24:25,176 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:24:25,176 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:24:25,178 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:24:25,186 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:24:25,191 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:24:25,214 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:24:25] "GET / HTTP/1.1" 200 -
2024-12-26 00:24:34,646 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /upload
2024-12-26 00:24:34,647 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:24:34] "[31m[1mPOST /upload HTTP/1.1[0m" 403 -
2024-12-26 00:24:38,162 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /upload
2024-12-26 00:24:38,163 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:24:38] "[31m[1mPOST /upload HTTP/1.1[0m" 403 -
2024-12-26 00:24:52,642 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:24:52] "GET / HTTP/1.1" 200 -
2024-12-26 00:24:52,729 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:24:52] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:24:52,746 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:24:52] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 00:24:58,160 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:24:58] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 00:33:27,418 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 00:33:28,389 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:33:29,074 - __main__ - INFO - Starting application...
2024-12-26 00:33:29,075 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:33:29,075 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:33:29,075 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:33:29,097 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:33:29,104 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:33:37,702 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:33:37] "GET / HTTP/1.1" 200 -
2024-12-26 00:33:37,834 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:33:37] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:33:37,836 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:33:37] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 00:33:41,847 - __main__ - INFO - File saved successfully: 875c389be7b34c4962d2b1e1d88510502cb3aa054a5a9595655510fbb43f5524.pdf
2024-12-26 00:33:41,876 - __main__ - INFO - Temporary file removed: 875c389be7b34c4962d2b1e1d88510502cb3aa054a5a9595655510fbb43f5524.pdf
2024-12-26 00:33:41,877 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:33:41] "POST /upload HTTP/1.1" 200 -
2024-12-26 00:33:59,212 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:33:59] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 00:34:04,671 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:34:04] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 00:34:06,403 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:34:06] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 00:34:06,603 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:34:06] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 00:34:17,660 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:34:17] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 00:34:19,146 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:34:19] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 00:34:19,638 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:34:19] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 00:34:19,840 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:34:19] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 00:35:08,536 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 00:35:08,633 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:35:10,382 - __main__ - INFO - Starting application...
2024-12-26 00:35:10,382 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:35:10,382 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:35:10,382 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:35:10,404 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:35:10,412 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:35:46,599 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 00:35:46,801 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:35:48,579 - __main__ - INFO - Starting application...
2024-12-26 00:35:48,580 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:35:48,580 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:35:48,581 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:35:48,600 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:35:48,607 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:35:58,086 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:35:58] "GET / HTTP/1.1" 200 -
2024-12-26 00:35:58,206 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:35:58] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:35:58,211 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:35:58] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 00:36:07,627 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:36:07] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 00:36:36,847 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 00:36:37,027 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:36:37,698 - __main__ - INFO - Starting application...
2024-12-26 00:36:37,698 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:36:37,698 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:36:37,700 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:36:37,722 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:36:37,729 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:36:43,465 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:36:43] "GET / HTTP/1.1" 200 -
2024-12-26 00:36:43,552 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:36:43] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:36:43,567 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:36:43] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 00:36:58,177 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:36:58] "GET / HTTP/1.1" 200 -
2024-12-26 00:36:58,195 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:36:58] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:36:58,197 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:36:58] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 00:37:01,548 - __main__ - INFO - File saved successfully: 2f854a294350146e0ee0f22fecf69690f62a8f1f549b3772d02cc0fed37f9c18.pdf
2024-12-26 00:37:01,575 - __main__ - INFO - Temporary file removed: 2f854a294350146e0ee0f22fecf69690f62a8f1f549b3772d02cc0fed37f9c18.pdf
2024-12-26 00:37:01,577 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:37:01] "POST /upload HTTP/1.1" 200 -
2024-12-26 00:37:13,181 - __main__ - INFO - File saved successfully: 291c2198c27e2a463f236f680bd7e6aa15d9757709bfc2c57dd29d95a452cb1f.pdf
2024-12-26 00:37:13,205 - __main__ - INFO - Temporary file removed: 291c2198c27e2a463f236f680bd7e6aa15d9757709bfc2c57dd29d95a452cb1f.pdf
2024-12-26 00:37:13,209 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:37:13] "POST /upload HTTP/1.1" 200 -
2024-12-26 00:37:31,470 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:37:31] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 00:42:37,401 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 00:42:37,478 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:42:39,101 - __main__ - INFO - Starting application...
2024-12-26 00:42:39,102 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:42:39,102 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:42:39,102 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:42:39,125 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:42:39,133 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:42:45,774 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:42:45] "GET / HTTP/1.1" 200 -
2024-12-26 00:42:45,882 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:42:45] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:42:45,885 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:42:45] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 00:42:51,473 - __main__ - INFO - File saved successfully: 258ba48a00d4f24cd7784d860199f43bc3571d5f64308b16942535485a8ab1dc.pdf
2024-12-26 00:42:51,509 - __main__ - INFO - Temporary file removed: 258ba48a00d4f24cd7784d860199f43bc3571d5f64308b16942535485a8ab1dc.pdf
2024-12-26 00:42:51,509 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:42:51] "POST /upload HTTP/1.1" 200 -
2024-12-26 00:42:57,575 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:42:57,575 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:42:57,575 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:42:57] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:42:57,575 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:42:57] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:42:59,971 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:42:59,971 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:42:59,973 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:42:59] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:42:59,974 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:42:59] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:43:00,875 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:43:00,876 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:43:00,877 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:43:00] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:43:00,878 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:43:00] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:43:01,168 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:43:01,170 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:43:01,170 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:43:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:43:01,171 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:43:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:43:01,421 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:43:01,422 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:43:01,423 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:43:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:43:01,424 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:43:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:43:01,627 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:43:01,627 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:43:01,629 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:43:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:43:01,631 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:43:01] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:43:07,160 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:43:07] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:43:14,747 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:43:14,750 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:43:14] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:45:49,135 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 00:45:49,333 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:45:51,071 - __main__ - INFO - Starting application...
2024-12-26 00:45:51,071 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:45:51,071 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:45:51,071 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:45:51,094 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:45:51,101 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:45:58,641 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:45:58] "GET / HTTP/1.1" 200 -
2024-12-26 00:45:58,759 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:45:58] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 00:45:58,764 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:45:58] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:46:03,486 - __main__ - INFO - File saved successfully: 86912b6f4857aa8e5e132291552b5a85a0987c2534e2c7b14b2c92004bef44a2.pdf
2024-12-26 00:46:03,509 - __main__ - INFO - Temporary file removed: 86912b6f4857aa8e5e132291552b5a85a0987c2534e2c7b14b2c92004bef44a2.pdf
2024-12-26 00:46:03,510 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:46:03] "POST /upload HTTP/1.1" 200 -
2024-12-26 00:46:10,731 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:46:10,735 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:46:10] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:46:17,084 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:46:17,086 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:46:17] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:46:34,958 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:46:34] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:46:39,816 - __main__ - ERROR - Error querying OpenAI GPT-3: 

You tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.

You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. 

Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`

A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742

2024-12-26 00:46:39,818 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:46:39] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:47:52,099 - __main__ - INFO - Starting application...
2024-12-26 00:47:52,099 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:47:52,099 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:47:52,099 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:47:52,134 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-26 00:47:52,134 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-26 00:47:52,136 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:47:53,716 - __main__ - INFO - Starting application...
2024-12-26 00:47:53,716 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:47:53,716 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:47:53,720 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:47:53,736 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:47:53,743 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:48:01,855 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:48:01] "GET / HTTP/1.1" 200 -
2024-12-26 00:48:01,981 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:48:01] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:48:01,982 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:48:01] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 00:48:06,926 - __main__ - INFO - File saved successfully: cf63aef68a2273df522ea85db16b537da72ad819156bcad3770749f42e752da6.pdf
2024-12-26 00:48:06,963 - __main__ - INFO - Temporary file removed: cf63aef68a2273df522ea85db16b537da72ad819156bcad3770749f42e752da6.pdf
2024-12-26 00:48:06,964 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:48:06] "POST /upload HTTP/1.1" 200 -
2024-12-26 00:48:15,403 - openai - INFO - error_code=model_not_found error_message='The model `text-davinci-003` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations' error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False
2024-12-26 00:48:15,404 - __main__ - ERROR - Error querying OpenAI GPT-3: The model `text-davinci-003` has been deprecated, learn more here: https://platform.openai.com/docs/deprecations
2024-12-26 00:48:15,405 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:48:15] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:50:53,591 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 00:50:53,865 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:50:55,644 - __main__ - INFO - Starting application...
2024-12-26 00:50:55,645 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:50:55,645 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:50:55,646 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:50:55,666 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:50:55,673 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:50:59,027 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:50:59] "GET / HTTP/1.1" 200 -
2024-12-26 00:50:59,133 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:50:59] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:50:59,141 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:50:59] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 00:51:02,686 - __main__ - INFO - File saved successfully: 754a44dfbcccdeb2fed37bc0beac97fd2d5600db1943752c8ba3d5133c9cda6a.pdf
2024-12-26 00:51:02,716 - __main__ - INFO - Temporary file removed: 754a44dfbcccdeb2fed37bc0beac97fd2d5600db1943752c8ba3d5133c9cda6a.pdf
2024-12-26 00:51:02,717 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:51:02] "POST /upload HTTP/1.1" 200 -
2024-12-26 00:51:09,992 - openai - INFO - error_code=insufficient_quota error_message='You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.' error_param=None error_type=insufficient_quota message='OpenAI API error received' stream_error=False
2024-12-26 00:51:09,998 - __main__ - ERROR - OpenAI API error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.
2024-12-26 00:51:09,998 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:51:09] "[35m[1mPOST /ask HTTP/1.1[0m" 500 -
2024-12-26 00:58:52,927 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 00:58:53,080 - werkzeug - INFO -  * Restarting with stat
2024-12-26 00:59:33,319 - __main__ - INFO - Starting application...
2024-12-26 00:59:33,319 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 00:59:33,319 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 00:59:33,321 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 00:59:33,330 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 00:59:33,336 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 00:59:33,370 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:59:33] "GET / HTTP/1.1" 200 -
2024-12-26 00:59:33,476 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:59:33] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 00:59:33,496 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 00:59:33] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 01:00:00,674 - __main__ - INFO - File saved successfully: c8ba09f0185e4bc6345c6da2dd2d513c8ce36b648e5e3a1090f61a5ef8297b33.pdf
2024-12-26 01:00:00,705 - __main__ - INFO - Temporary file removed: c8ba09f0185e4bc6345c6da2dd2d513c8ce36b648e5e3a1090f61a5ef8297b33.pdf
2024-12-26 01:00:00,707 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:00:00] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:00:10,389 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:00:10] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:00:10,390 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:00:10] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:00:32,277 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:00:32] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:00:32,284 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:00:32] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:00:48,869 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:00:48] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:00:48,871 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:00:48] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:00:55,749 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:00:55] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:00:55,749 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:00:55] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:01:05,316 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:01:05] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:01:05,324 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:01:05] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:01:24,335 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:01:24] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:01:24,338 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:01:24] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:01:30,916 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:01:30] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:01:30,920 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:01:30] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:01:41,230 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:01:41] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:01:41,231 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:01:41] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:01:44,036 - __main__ - INFO - File saved successfully: d318acc9d75de68f0f33dd65485552883faabeaeab7925c7a0d723720ff6f3ce.pdf
2024-12-26 01:01:44,061 - __main__ - INFO - Temporary file removed: d318acc9d75de68f0f33dd65485552883faabeaeab7925c7a0d723720ff6f3ce.pdf
2024-12-26 01:01:44,062 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:01:44] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:01:55,129 - __main__ - INFO - File saved successfully: d43c0b6741e225f93f9146bd8d377dab68b6c2e5eee796217fd5644f92305a14.pdf
2024-12-26 01:01:55,458 - __main__ - INFO - Temporary file removed: d43c0b6741e225f93f9146bd8d377dab68b6c2e5eee796217fd5644f92305a14.pdf
2024-12-26 01:01:55,458 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:01:55] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:02:08,540 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:02:08] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:02:08,557 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:02:08] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:02:20,837 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:02:20] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:02:20,839 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:02:20] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:02:29,920 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:02:29] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:02:29,927 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:02:29] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:02:40,055 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:02:40] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:02:40,076 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:02:40] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:02:53,610 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:02:53] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:02:53,621 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:02:53] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:05:33,179 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 01:05:34,052 - werkzeug - INFO -  * Restarting with stat
2024-12-26 01:10:32,782 - __main__ - INFO - Starting application...
2024-12-26 01:10:32,783 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 01:10:32,783 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 01:10:32,783 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 01:10:32,802 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-26 01:10:32,803 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-26 01:10:32,805 - werkzeug - INFO -  * Restarting with stat
2024-12-26 01:10:42,736 - __main__ - INFO - Starting application...
2024-12-26 01:10:42,737 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 01:10:42,737 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 01:10:42,738 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 01:10:42,749 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 01:10:42,755 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 01:11:05,158 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:11:05] "GET / HTTP/1.1" 200 -
2024-12-26 01:11:05,306 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:11:05] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 01:11:05,306 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:11:05] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 01:11:16,148 - __main__ - INFO - File saved successfully: 058207ebed06570143067dc28d4ef988fca8269f705f45c59c7ad33ac074e459.pdf
2024-12-26 01:11:16,171 - __main__ - INFO - Temporary file removed: 058207ebed06570143067dc28d4ef988fca8269f705f45c59c7ad33ac074e459.pdf
2024-12-26 01:11:16,172 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:11:16] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:11:30,030 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:11:30] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:11:30,056 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:11:30] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:11:42,743 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:11:42] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:11:42,745 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:11:42] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:11:54,141 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:11:54] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:11:54,142 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:11:54] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:12:12,286 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:12:12] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:12:12,288 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:12:12] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:12:43,673 - __main__ - INFO - File saved successfully: 5f1b1daa2d575cda1100a76b1b60f52786007d2ca24fc3cc6caf7ba2c05d1b9f.pdf
2024-12-26 01:12:44,083 - __main__ - INFO - Temporary file removed: 5f1b1daa2d575cda1100a76b1b60f52786007d2ca24fc3cc6caf7ba2c05d1b9f.pdf
2024-12-26 01:12:44,084 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:12:44] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:13:00,683 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:13:00] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:13:00,683 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:13:00] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:13:20,241 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:13:20] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:13:20,273 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:13:20] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:13:30,823 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:13:30] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:13:30,851 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:13:30] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:13:39,273 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:13:39] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:13:39,273 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:13:39] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:16:22,640 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 01:16:23,675 - werkzeug - INFO -  * Restarting with stat
2024-12-26 01:16:32,044 - __main__ - INFO - Starting application...
2024-12-26 01:16:32,045 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 01:16:32,045 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 01:16:32,045 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 01:16:32,054 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 01:16:32,059 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 01:16:32,084 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:16:32] "GET / HTTP/1.1" 200 -
2024-12-26 01:16:32,210 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:16:32] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 01:16:32,214 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:16:32] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 01:16:41,057 - __main__ - INFO - File saved successfully: 8627edfcfe1ba0de58d8966ed3c21e4cfbd7dfa6af0b0a5b90e92463e3f88a7a.pdf
2024-12-26 01:16:41,085 - __main__ - INFO - Temporary file removed: 8627edfcfe1ba0de58d8966ed3c21e4cfbd7dfa6af0b0a5b90e92463e3f88a7a.pdf
2024-12-26 01:16:41,087 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:16:41] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:16:47,327 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:16:47] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:16:47,328 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:16:47] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:16:54,911 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:16:54] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:16:54,927 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:16:54] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:17:01,923 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:17:01] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:17:01,942 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:17:01] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:17:07,207 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:17:07] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:17:07,226 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:17:07] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:17:40,747 - __main__ - INFO - File saved successfully: 6545c4489b19dfd9bf070c76bb58f7f1f68999d1d655eb9930b5ccc2545b26b0.pdf
2024-12-26 01:17:41,089 - __main__ - INFO - Temporary file removed: 6545c4489b19dfd9bf070c76bb58f7f1f68999d1d655eb9930b5ccc2545b26b0.pdf
2024-12-26 01:17:41,090 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:17:41] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:17:49,134 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:17:49] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:17:49,143 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:17:49] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:17:56,228 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:17:56] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:17:56,229 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:17:56] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:18:03,278 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:18:03] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:18:03,299 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:18:03] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:18:16,026 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:18:16] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:18:16,037 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:18:16] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:18:23,555 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:18:23] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:18:23,566 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:18:23] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:18:40,468 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:18:40] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:18:40,476 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:18:40] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:19:09,292 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:19:09] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:19:09,297 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:19:09] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:22:16,848 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 01:22:17,714 - werkzeug - INFO -  * Restarting with stat
2024-12-26 01:22:25,976 - __main__ - INFO - Starting application...
2024-12-26 01:22:25,977 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 01:22:25,977 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 01:22:25,977 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 01:22:25,984 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 01:22:25,988 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 01:22:37,221 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:22:37] "GET / HTTP/1.1" 200 -
2024-12-26 01:22:37,355 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:22:37] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 01:22:37,358 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:22:37] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 01:22:42,096 - __main__ - INFO - File saved successfully: b377ed961264170e7c75f7d0ab64882300ac3900257a7fdfcfc38724141a812d.pdf
2024-12-26 01:22:42,417 - __main__ - INFO - Temporary file removed: b377ed961264170e7c75f7d0ab64882300ac3900257a7fdfcfc38724141a812d.pdf
2024-12-26 01:22:42,418 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:22:42] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:22:58,771 - __main__ - ERROR - Error querying Hugging Face API: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2
2024-12-26 01:22:58,774 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:22:58] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:23:08,532 - __main__ - ERROR - Error querying Hugging Face API: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2
2024-12-26 01:23:08,533 - __main__ - ERROR - Error querying Hugging Face API: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2
2024-12-26 01:23:08,535 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:23:08] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:23:08,536 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:23:08] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:23:19,158 - __main__ - ERROR - Error querying Hugging Face API: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2
2024-12-26 01:23:19,161 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:23:19] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:23:19,188 - __main__ - ERROR - Error querying Hugging Face API: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/gpt2
2024-12-26 01:23:19,189 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:23:19] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:28:57,380 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 01:28:58,337 - werkzeug - INFO -  * Restarting with stat
2024-12-26 01:29:07,210 - __main__ - INFO - Starting application...
2024-12-26 01:29:07,210 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 01:29:07,210 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 01:29:07,210 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 01:29:07,216 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 01:29:07,224 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 01:29:08,011 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /ask
2024-12-26 01:29:08,013 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:08] "[31m[1mPOST /ask HTTP/1.1[0m" 403 -
2024-12-26 01:29:09,117 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /ask
2024-12-26 01:29:09,118 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:09] "[31m[1mPOST /ask HTTP/1.1[0m" 403 -
2024-12-26 01:29:09,949 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /ask
2024-12-26 01:29:09,950 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:09] "[31m[1mPOST /ask HTTP/1.1[0m" 403 -
2024-12-26 01:29:12,848 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:12] "GET / HTTP/1.1" 200 -
2024-12-26 01:29:12,979 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:12] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 01:29:12,981 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:12] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 01:29:22,464 - __main__ - INFO - File saved successfully: 94a041c7af010108a90ddbcad1bf317e7245a0449c2c7d6dce3e07960d3387c5.pdf
2024-12-26 01:29:22,492 - __main__ - INFO - Temporary file removed: 94a041c7af010108a90ddbcad1bf317e7245a0449c2c7d6dce3e07960d3387c5.pdf
2024-12-26 01:29:22,493 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:22] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:29:26,744 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:26] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:29:26,744 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:26] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:29:38,725 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:38] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:29:53,540 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:29:53] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:30:05,957 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:30:05] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:30:05,958 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:30:05] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:30:17,741 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:30:17] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:30:32,740 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:30:32] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:30:52,275 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:30:52] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:30:52,279 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:30:52] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:31:16,336 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:31:16] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:31:21,536 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:31:21] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:31:25,715 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:31:25] "GET / HTTP/1.1" 200 -
2024-12-26 01:31:25,736 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:31:25] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 01:31:25,745 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:31:25] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 01:31:42,754 - __main__ - INFO - File saved successfully: 691eb2989e0dbb7bef93b9811b712f173ddd494489e072551c6d4d1d25a86511.pdf
2024-12-26 01:31:43,059 - __main__ - INFO - Temporary file removed: 691eb2989e0dbb7bef93b9811b712f173ddd494489e072551c6d4d1d25a86511.pdf
2024-12-26 01:31:43,060 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:31:43] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:32:03,011 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:32:03] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:32:10,234 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:32:10] "GET / HTTP/1.1" 200 -
2024-12-26 01:32:10,252 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:32:10] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 01:32:10,258 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:32:10] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 01:34:37,784 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 01:34:38,778 - werkzeug - INFO -  * Restarting with stat
2024-12-26 01:34:46,748 - __main__ - INFO - Starting application...
2024-12-26 01:34:46,750 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 01:34:46,750 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 01:34:46,751 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 01:34:46,761 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 01:34:46,768 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 01:35:02,088 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:35:02] "GET / HTTP/1.1" 200 -
2024-12-26 01:35:02,216 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:35:02] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 01:35:02,217 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:35:02] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 01:35:08,848 - __main__ - INFO - File saved successfully: 470533ef9459e1f290004841076180c0d36f0383db79adde9811e97b9d42e091.pdf
2024-12-26 01:35:09,149 - __main__ - INFO - Temporary file removed: 470533ef9459e1f290004841076180c0d36f0383db79adde9811e97b9d42e091.pdf
2024-12-26 01:35:09,151 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:35:09] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:35:24,311 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:35:24] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:35:39,413 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:35:39] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:35:56,567 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:35:56] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:35:56,584 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:35:56] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:36:02,824 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:36:02] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:39:03,991 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 01:39:04,851 - werkzeug - INFO -  * Restarting with stat
2024-12-26 01:39:13,338 - __main__ - INFO - Starting application...
2024-12-26 01:39:13,338 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 01:39:13,339 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 01:39:13,339 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 01:39:13,347 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 01:39:13,354 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 01:39:23,455 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 01:39:24,493 - werkzeug - INFO -  * Restarting with stat
2024-12-26 01:39:36,832 - __main__ - INFO - Starting application...
2024-12-26 01:39:36,832 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 01:39:36,840 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 01:39:36,840 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 01:39:36,850 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 01:39:36,860 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 01:39:36,898 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:39:36] "GET / HTTP/1.1" 200 -
2024-12-26 01:39:37,061 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:39:37] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 01:39:37,075 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:39:37] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 01:39:43,115 - __main__ - INFO - File saved successfully: 16f224610d20653cc52c4e5d2114fed88d5558f7afe110c796fe6695388c33c5.pdf
2024-12-26 01:39:43,559 - __main__ - INFO - Temporary file removed: 16f224610d20653cc52c4e5d2114fed88d5558f7afe110c796fe6695388c33c5.pdf
2024-12-26 01:39:43,560 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:39:43] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:39:58,142 - __main__ - ERROR - Error querying LLM API: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/gpt2
2024-12-26 01:39:58,143 - __main__ - ERROR - Error querying LLM API: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/gpt2
2024-12-26 01:39:58,145 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:39:58] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:39:58,145 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:39:58] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:40:16,560 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:40:16] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:40:16,580 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:40:16] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:40:37,220 - __main__ - ERROR - Error querying LLM API: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/gpt2
2024-12-26 01:40:37,220 - __main__ - ERROR - Error querying LLM API: 422 Client Error: Unprocessable Entity for url: https://api-inference.huggingface.co/models/gpt2
2024-12-26 01:40:37,220 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:40:37] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:40:37,223 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:40:37] "[33mPOST /ask HTTP/1.1[0m" 404 -
2024-12-26 01:40:40,599 - __main__ - INFO - File saved successfully: 6aeb6d3887c36179f0bc615bc4f31327c8a75165cd0bc89843682d44f68cc63c.pdf
2024-12-26 01:40:41,059 - __main__ - INFO - Temporary file removed: 6aeb6d3887c36179f0bc615bc4f31327c8a75165cd0bc89843682d44f68cc63c.pdf
2024-12-26 01:40:41,062 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:40:41] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:40:57,342 - __main__ - INFO - File saved successfully: c79a640b93d57c4f912e7c857ce7baa2c432a2d8fc7c513c16b43183e30ed6b4.pdf
2024-12-26 01:40:57,376 - __main__ - INFO - Temporary file removed: c79a640b93d57c4f912e7c857ce7baa2c432a2d8fc7c513c16b43183e30ed6b4.pdf
2024-12-26 01:40:57,377 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:40:57] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:41:04,014 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:41:04] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:41:04,033 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:41:04] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:41:17,388 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:41:17] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:41:29,808 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:41:29] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:42:05,401 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:42:05] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:42:05,421 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:42:05] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:42:23,715 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:42:23] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:42:23,728 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:42:23] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:42:41,827 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:42:41] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:42:57,696 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:42:57] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:45:36,297 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 01:45:37,299 - werkzeug - INFO -  * Restarting with stat
2024-12-26 01:54:55,234 - __main__ - INFO - Successfully loaded QA model
2024-12-26 01:54:55,238 - __main__ - INFO - Starting application...
2024-12-26 01:54:55,239 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 01:54:55,239 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 01:54:55,239 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 01:54:55,265 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-26 01:54:55,265 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-26 01:54:55,269 - werkzeug - INFO -  * Restarting with stat
2024-12-26 01:55:07,887 - __main__ - INFO - Successfully loaded QA model
2024-12-26 01:55:07,895 - __main__ - INFO - Starting application...
2024-12-26 01:55:07,895 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 01:55:07,898 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 01:55:07,899 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 01:55:07,920 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 01:55:07,931 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 01:55:07,970 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:07] "GET / HTTP/1.1" 200 -
2024-12-26 01:55:08,095 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:08] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 01:55:08,125 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:08] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 01:55:13,358 - __main__ - INFO - File saved successfully: 5055071e97b113284b803970340db4208a2e7de540b00df83a1a69e3a0d3da48.pdf
2024-12-26 01:55:13,390 - __main__ - INFO - Temporary file removed: 5055071e97b113284b803970340db4208a2e7de540b00df83a1a69e3a0d3da48.pdf
2024-12-26 01:55:13,395 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:13] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:55:17,477 - __main__ - WARNING - Malicious input detected in question: who is elara?
2024-12-26 01:55:17,477 - __main__ - WARNING - Malicious input detected in question: who is elara?
2024-12-26 01:55:17,481 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:17] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 01:55:17,481 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:17] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 01:55:27,967 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:27] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:55:27,967 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:27] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:55:35,474 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:35] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:55:35,479 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:35] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:55:40,482 - __main__ - WARNING - Malicious input detected in question: what did elara discover?
2024-12-26 01:55:40,484 - __main__ - WARNING - Malicious input detected in question: what did elara discover?
2024-12-26 01:55:40,484 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:40] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 01:55:40,485 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:40] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 01:55:47,119 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:47] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:55:47,134 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:55:47] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:56:17,262 - __main__ - INFO - File saved successfully: ecb2b16c8d3a39d52157a55eebdba99641ee3af2a8fc731e5962977f4dc13a3b.pdf
2024-12-26 01:56:17,739 - __main__ - INFO - Temporary file removed: ecb2b16c8d3a39d52157a55eebdba99641ee3af2a8fc731e5962977f4dc13a3b.pdf
2024-12-26 01:56:17,740 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:56:17] "POST /upload HTTP/1.1" 200 -
2024-12-26 01:56:25,955 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:56:25] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:56:26,000 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:56:26] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:56:48,710 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:56:48] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:56:49,304 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:56:49] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:57:21,952 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:57:21] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:57:23,632 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:57:23] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:57:24,182 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:57:24] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:57:24,200 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:57:24] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:57:31,843 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:57:31] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:57:32,134 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:57:32] "POST /ask HTTP/1.1" 200 -
2024-12-26 01:59:41,702 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:59:41] "GET / HTTP/1.1" 200 -
2024-12-26 01:59:41,836 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:59:41] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 01:59:41,839 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 01:59:41] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 02:00:02,075 - __main__ - INFO - File saved successfully: 83d157f99be21c8a6ab5dd627921f75560e0c141162794d8e7c97af38e405dbd.pdf
2024-12-26 02:00:05,886 - __main__ - INFO - Temporary file removed: 83d157f99be21c8a6ab5dd627921f75560e0c141162794d8e7c97af38e405dbd.pdf
2024-12-26 02:00:05,892 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:00:05] "POST /upload HTTP/1.1" 200 -
2024-12-26 02:01:17,177 - __main__ - WARNING - Malicious input detected in question: select * from users?
2024-12-26 02:01:17,189 - __main__ - WARNING - Malicious input detected in question: select * from users?
2024-12-26 02:01:17,192 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:01:17] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:01:17,198 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:01:17] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:01:21,152 - __main__ - WARNING - Malicious input detected in question: select * from users
2024-12-26 02:01:21,170 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:01:21] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:01:21,172 - __main__ - WARNING - Malicious input detected in question: select * from users
2024-12-26 02:01:21,180 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:01:21] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:01:50,983 - __main__ - WARNING - Malicious input detected in question: what are the languages known?
2024-12-26 02:01:50,999 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:01:50] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:01:51,000 - __main__ - WARNING - Malicious input detected in question: what are the languages known?
2024-12-26 02:01:51,008 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:01:51] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:02:07,360 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:02:07] "POST /ask HTTP/1.1" 200 -
2024-12-26 02:02:07,405 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:02:07] "POST /ask HTTP/1.1" 200 -
2024-12-26 02:02:27,719 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 02:02:34,758 - werkzeug - INFO -  * Restarting with stat
2024-12-26 02:03:48,626 - __main__ - INFO - Successfully loaded QA model
2024-12-26 02:03:48,642 - __main__ - INFO - Starting application...
2024-12-26 02:03:48,646 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 02:03:48,649 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 02:03:48,653 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 02:03:48,729 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 02:03:48,774 - werkzeug - INFO -  * Debugger PIN: 124-268-802
2024-12-26 02:03:48,915 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /ask
2024-12-26 02:03:48,918 - chatbot - WARNING - Forbidden (CSRF token missing or incorrect.): /ask
2024-12-26 02:03:48,931 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:03:48] "[31m[1mPOST /ask HTTP/1.1[0m" 403 -
2024-12-26 02:03:48,941 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:03:48] "[31m[1mPOST /ask HTTP/1.1[0m" 403 -
2024-12-26 02:07:39,452 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:07:39] "GET / HTTP/1.1" 200 -
2024-12-26 02:07:40,412 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:07:40] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 02:07:40,428 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:07:40] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 02:09:14,883 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:09:14] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 02:09:18,604 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:09:18] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 02:09:19,530 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:09:19] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 02:09:19,718 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:09:19] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 02:09:24,703 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:09:24] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 02:09:25,333 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:09:25] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 02:09:25,576 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:09:25] "[31m[1mPOST /upload HTTP/1.1[0m" 400 -
2024-12-26 02:09:57,057 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:09:57] "GET / HTTP/1.1" 200 -
2024-12-26 02:09:57,071 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:09:57] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 02:09:57,074 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:09:57] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 02:10:00,610 - __main__ - INFO - File saved successfully: 51e7344d3e0c4ca32e192b4661d6bf3a8c1515745bc821a556d8fbe5ebdea73f.pdf
2024-12-26 02:10:00,623 - __main__ - INFO - Temporary file removed: 51e7344d3e0c4ca32e192b4661d6bf3a8c1515745bc821a556d8fbe5ebdea73f.pdf
2024-12-26 02:10:00,623 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:10:00] "POST /upload HTTP/1.1" 200 -
2024-12-26 02:10:16,404 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:10:16] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:10:16,405 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:10:16] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:10:19,252 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:10:19] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:10:19,253 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:10:19] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:10:34,397 - __main__ - INFO - File saved successfully: 8c5f85ce5666ebcf6510837bc3accc57ba18c390f8318b860f4b144740f29f69.pdf
2024-12-26 02:10:34,581 - __main__ - INFO - Temporary file removed: 8c5f85ce5666ebcf6510837bc3accc57ba18c390f8318b860f4b144740f29f69.pdf
2024-12-26 02:10:34,583 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:10:34] "POST /upload HTTP/1.1" 200 -
2024-12-26 02:10:48,788 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:10:48] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:10:51,801 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:10:51] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:10:52,790 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:10:52] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:10:53,020 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:10:53] "[31m[1mPOST /ask HTTP/1.1[0m" 400 -
2024-12-26 02:11:20,498 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:11:20] "GET / HTTP/1.1" 200 -
2024-12-26 02:11:20,508 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:11:20] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 02:11:20,510 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:11:20] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 02:11:33,673 - __main__ - INFO - File saved successfully: e706fd409952fa412d6a0ca20d5e682e6546110adef019bfd6b5fdeef2b82256.pdf
2024-12-26 02:11:34,010 - __main__ - INFO - Temporary file removed: e706fd409952fa412d6a0ca20d5e682e6546110adef019bfd6b5fdeef2b82256.pdf
2024-12-26 02:11:34,010 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:11:34] "POST /upload HTTP/1.1" 200 -
2024-12-26 02:11:57,012 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:11:57] "POST /ask HTTP/1.1" 200 -
2024-12-26 02:12:07,808 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:12:07] "POST /ask HTTP/1.1" 200 -
2024-12-26 02:12:14,992 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 02:12:14] "POST /ask HTTP/1.1" 200 -
2024-12-26 07:52:28,937 - __main__ - INFO - Successfully loaded QA model
2024-12-26 07:59:26,145 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:02:15,735 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:02:15,738 - __main__ - INFO - Starting application...
2024-12-26 08:02:15,738 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:02:15,738 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:02:15,738 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:02:15,758 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-26 08:02:15,758 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-26 08:02:15,761 - werkzeug - INFO -  * Restarting with stat
2024-12-26 08:02:17,165 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:02:18,986 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:02:20,786 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:02:22,254 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:02:22,256 - __main__ - INFO - Starting application...
2024-12-26 08:02:22,256 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:02:22,256 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:02:22,256 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:02:22,261 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 08:02:22,265 - werkzeug - INFO -  * Debugger PIN: 921-300-071
2024-12-26 08:02:26,585 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:02:27,562 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:17:09,447 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:17:11,671 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:17:16,466 - __main__ - ERROR - Error loading RAG model: The repository for wiki_dpr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wiki_dpr.
Please pass the argument `trust_remote_code=True` to allow custom code to be run.
2024-12-26 08:17:16,474 - __main__ - INFO - Starting application...
2024-12-26 08:17:16,475 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:17:16,475 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:17:16,475 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:17:16,485 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-26 08:17:16,486 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-26 08:17:16,487 - werkzeug - INFO -  * Restarting with stat
2024-12-26 08:17:17,037 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:17:18,435 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:17:23,369 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:17:23,511 - __mp_main__ - ERROR - Error loading RAG model: The repository for wiki_dpr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wiki_dpr.
Please pass the argument `trust_remote_code=True` to allow custom code to be run.
2024-12-26 08:17:26,298 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:17:30,927 - __main__ - ERROR - Error loading RAG model: The repository for wiki_dpr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wiki_dpr.
Please pass the argument `trust_remote_code=True` to allow custom code to be run.
2024-12-26 08:17:30,936 - __main__ - INFO - Starting application...
2024-12-26 08:17:30,936 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:17:30,936 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:17:30,936 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:17:30,941 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 08:17:30,944 - werkzeug - INFO -  * Debugger PIN: 921-300-071
2024-12-26 08:17:31,383 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:17:33,571 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:17:37,590 - __mp_main__ - ERROR - Error loading RAG model: The repository for wiki_dpr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wiki_dpr.
Please pass the argument `trust_remote_code=True` to allow custom code to be run.
2024-12-26 08:26:50,737 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:26:53,265 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:26:53,267 - __main__ - INFO - Starting application...
2024-12-26 08:26:53,267 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:26:53,267 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:26:53,267 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:26:53,276 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-26 08:26:53,276 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-26 08:26:53,278 - werkzeug - INFO -  * Restarting with stat
2024-12-26 08:26:57,344 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:26:58,305 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:26:59,089 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:27:01,351 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:27:01,353 - __main__ - INFO - Starting application...
2024-12-26 08:27:01,353 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:27:01,353 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:27:01,354 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:27:01,358 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 08:27:01,361 - werkzeug - INFO -  * Debugger PIN: 921-300-071
2024-12-26 08:27:05,244 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:27:06,233 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:32:31,181 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:32:32,856 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:32:32,858 - __main__ - INFO - Starting application...
2024-12-26 08:32:32,858 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:32:32,858 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:32:32,858 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:32:32,873 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-26 08:32:32,873 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-26 08:32:32,874 - werkzeug - INFO -  * Restarting with stat
2024-12-26 08:32:37,245 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:32:38,229 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:32:38,352 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:32:40,317 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:32:40,319 - __main__ - INFO - Starting application...
2024-12-26 08:32:40,320 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:32:40,320 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:32:40,320 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:32:40,326 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 08:32:40,330 - werkzeug - INFO -  * Debugger PIN: 921-300-071
2024-12-26 08:32:40,348 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:32:40] "GET / HTTP/1.1" 200 -
2024-12-26 08:32:40,461 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:32:40] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 08:32:40,464 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:32:40] "GET /static/css/style.css HTTP/1.1" 200 -
2024-12-26 08:32:40,519 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:32:40] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-12-26 08:32:44,384 - __main__ - INFO - File saved successfully: 9f6a949a5f2529d4dcbd12ea03214ca74c1918369c5ee69fe45d1e4afc1a8f99
2024-12-26 08:32:44,411 - __main__ - INFO - Temporary file removed: 9f6a949a5f2529d4dcbd12ea03214ca74c1918369c5ee69fe45d1e4afc1a8f99
2024-12-26 08:32:44,411 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:32:44] "POST /upload HTTP/1.1" 200 -
2024-12-26 08:32:45,303 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:32:46,768 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:32:55,497 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:32:55] "POST /summarize HTTP/1.1" 200 -
2024-12-26 08:33:29,919 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:33:29] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:33:43,169 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:33:43] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:33:47,079 - __main__ - WARNING - Potential hallucination detected.
2024-12-26 08:33:47,079 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:33:47] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:33:47,082 - __main__ - WARNING - Potential hallucination detected.
2024-12-26 08:33:47,082 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:33:47] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:34:01,863 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:34:01] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:34:01,865 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:34:01] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:34:12,468 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:34:12] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:34:12,476 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:34:12] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:35:18,557 - __main__ - INFO - File saved successfully: 9aed9200426ae7e1cba349afc05d7bf424a370f72027381f47567059939c0d0b
2024-12-26 08:35:18,885 - __main__ - INFO - Temporary file removed: 9aed9200426ae7e1cba349afc05d7bf424a370f72027381f47567059939c0d0b
2024-12-26 08:35:18,885 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:35:18] "POST /upload HTTP/1.1" 200 -
2024-12-26 08:35:28,342 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:35:28] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:35:28,344 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:35:28] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:35:39,992 - __main__ - WARNING - Potential hallucination detected.
2024-12-26 08:35:39,994 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:35:39] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:35:40,039 - __main__ - WARNING - Potential hallucination detected.
2024-12-26 08:35:40,040 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:35:40] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:38:50,002 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 08:38:51,173 - werkzeug - INFO -  * Restarting with stat
2024-12-26 08:39:00,181 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:39:03,303 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:39:03,308 - __main__ - INFO - Starting application...
2024-12-26 08:39:03,309 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:39:03,309 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:39:03,310 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:39:03,318 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 08:39:03,324 - werkzeug - INFO -  * Debugger PIN: 921-300-071
2024-12-26 08:39:04,296 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:39:04] "GET / HTTP/1.1" 200 -
2024-12-26 08:39:04,533 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:39:04] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 08:39:04,536 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:39:04] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 08:39:08,997 - __main__ - INFO - File saved successfully: ee51ed760ff7f894da378e5cfeaa24a81697de10d64e7d47eaf1115dd151cf01
2024-12-26 08:39:09,394 - __main__ - INFO - Temporary file removed: ee51ed760ff7f894da378e5cfeaa24a81697de10d64e7d47eaf1115dd151cf01
2024-12-26 08:39:09,395 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:39:09] "POST /upload HTTP/1.1" 200 -
2024-12-26 08:39:10,928 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:39:11,758 - __main__ - ERROR - Summarization error: index out of range in self
2024-12-26 08:39:11,762 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:39:11] "[35m[1mPOST /summarize HTTP/1.1[0m" 500 -
2024-12-26 08:39:11,923 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:39:22,858 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:39:22] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:39:33,455 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:39:33] "POST /ask HTTP/1.1" 200 -
2024-12-26 08:39:41,999 - __main__ - INFO - File saved successfully: eb9d405514bfe12067ed456dce9d21a80664f96f907946afb0505d6180403329
2024-12-26 08:39:42,050 - __main__ - INFO - Temporary file removed: eb9d405514bfe12067ed456dce9d21a80664f96f907946afb0505d6180403329
2024-12-26 08:39:42,051 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:39:42] "POST /upload HTTP/1.1" 200 -
2024-12-26 08:39:51,834 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:39:51] "POST /summarize HTTP/1.1" 200 -
2024-12-26 08:44:13,150 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:44:13] "GET / HTTP/1.1" 200 -
2024-12-26 08:44:13,245 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:44:13] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 08:44:13,245 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:44:13] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 08:45:17,498 - werkzeug - INFO -  * Detected change in 'D:\\Chatbot\\Chatbot\\chatbot_system\\backend\\chatbot.py', reloading
2024-12-26 08:45:18,820 - werkzeug - INFO -  * Restarting with stat
2024-12-26 08:45:27,712 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:45:30,263 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:45:30,266 - __main__ - INFO - Starting application...
2024-12-26 08:45:30,266 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:45:30,267 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:45:30,267 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:45:30,295 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 08:45:30,301 - werkzeug - INFO -  * Debugger PIN: 921-300-071
2024-12-26 08:45:30,333 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:45:30] "GET / HTTP/1.1" 200 -
2024-12-26 08:45:30,515 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:45:30] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 08:45:30,523 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:45:30] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-12-26 08:45:36,743 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:45:37,837 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:46:45,624 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:46:48,021 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:46:48,025 - __main__ - INFO - Starting application...
2024-12-26 08:46:48,026 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:46:48,026 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:46:48,027 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:46:48,059 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-26 08:46:48,059 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-12-26 08:46:48,061 - werkzeug - INFO -  * Restarting with stat
2024-12-26 08:46:55,775 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:46:56,415 - __main__ - INFO - Successfully loaded QA model
2024-12-26 08:46:56,929 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:46:58,580 - __main__ - INFO - Successfully loaded summarization model
2024-12-26 08:46:58,584 - __main__ - INFO - Starting application...
2024-12-26 08:46:58,584 - __main__ - INFO - Template folder: D:\Chatbot\Chatbot\chatbot_system\frontend\templates
2024-12-26 08:46:58,584 - __main__ - INFO - Static folder: D:\Chatbot\Chatbot\chatbot_system\frontend\static
2024-12-26 08:46:58,584 - __main__ - INFO - Upload folder: D:\Chatbot\Chatbot\chatbot_system\temp
2024-12-26 08:46:58,593 - werkzeug - WARNING -  * Debugger is active!
2024-12-26 08:46:58,597 - werkzeug - INFO -  * Debugger PIN: 921-300-071
2024-12-26 08:46:58,623 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:46:58] "GET / HTTP/1.1" 200 -
2024-12-26 08:46:58,772 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:46:58] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 08:46:58,774 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:46:58] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 08:47:05,344 - __mp_main__ - INFO - Successfully loaded QA model
2024-12-26 08:47:07,265 - __mp_main__ - ERROR - Error loading summarization model: Could not load model sshleifer/distilbart-cnn-12-6 with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSeq2SeqLM'>, <class 'transformers.models.bart.modeling_bart.BartForConditionalGeneration'>). See the original errors:

while loading with AutoModelForSeq2SeqLM, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.

while loading with BartForConditionalGeneration, an error is thrown:
Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3897, in from_pretrained
    ).start()
      ^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\process.py", line 121, in start
    self._popen = self._Popen(self)
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\context.py", line 337, in _Popen
    return Popen(process_obj)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\popen_spawn_win32.py", line 46, in __init__
    prep_data = spawn.get_preparation_data(process_obj._name)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 164, in get_preparation_data
    _check_not_importing_main()
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\multiprocessing\spawn.py", line 140, in _check_not_importing_main
    raise RuntimeError('''
RuntimeError: 
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.

        To fix this issue, refer to the "Safe importing of main module"
        section in https://docs.python.org/3/library/multiprocessing.html
        

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\pipelines\base.py", line 289, in infer_framework_load_model
    model = model_class.from_pretrained(model, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ksjyo\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\modeling_utils.py", line 3941, in from_pretrained
    raise EnvironmentError(
OSError: Can't load the model for 'sshleifer/distilbart-cnn-12-6'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'sshleifer/distilbart-cnn-12-6' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.



2024-12-26 08:48:39,423 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:48:39] "GET / HTTP/1.1" 200 -
2024-12-26 08:48:39,502 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:48:39] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 08:48:39,502 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:48:39] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 08:49:16,860 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:49:16] "GET / HTTP/1.1" 200 -
2024-12-26 08:49:16,946 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:49:16] "[36mGET /static/css/style.css HTTP/1.1[0m" 304 -
2024-12-26 08:49:16,946 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:49:16] "GET /static/js/main.js HTTP/1.1" 200 -
2024-12-26 08:49:21,124 - __main__ - INFO - File saved successfully: 5f4d0aa7b18d886fcbc9fd2053d2126fe1d74b2d57f45af48ac866dde75373c4
2024-12-26 08:49:21,160 - __main__ - INFO - Temporary file removed: 5f4d0aa7b18d886fcbc9fd2053d2126fe1d74b2d57f45af48ac866dde75373c4
2024-12-26 08:49:21,160 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:49:21] "POST /upload HTTP/1.1" 200 -
2024-12-26 08:49:35,394 - werkzeug - INFO - 127.0.0.1 - - [26/Dec/2024 08:49:35] "POST /summarize HTTP/1.1" 200 -
